"""
AIæ™ºèƒ½åŒ¹é…å™¨
ç”¨äºå¤„ç†ä»£ç åŒ¹é…å¤±è´¥çš„é›¶ä»¶
"""

import json
import re
from typing import List, Dict
from openai import OpenAI
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥æç¤ºè¯
from prompts.agent_2_bom_3d_matching import (
    build_ai_matching_prompt,
    AI_MATCHING_SYSTEM_PROMPT
)


class AIBOMMatcher:
    """AIæ™ºèƒ½BOMåŒ¹é…å™¨ï¼ˆä½¿ç”¨Gemini 2.5 Flashï¼‰"""

    def __init__(self, api_key: str = None):
        # ä½¿ç”¨Gemini 2.5 Flashï¼ˆé€šè¿‡OpenRouterï¼‰
        self.api_key = api_key or os.getenv("OPENROUTER_API_KEY")
        if not self.api_key:
            raise ValueError("éœ€è¦è®¾ç½®OPENROUTER_API_KEYç¯å¢ƒå˜é‡æˆ–ä¼ å…¥api_keyå‚æ•°")

        self.client = OpenAI(
            api_key=self.api_key,
            base_url="https://openrouter.ai/api/v1"
        )
        self.model = "google/gemini-2.5-flash-preview-09-2025"  # å’Œå…¶ä»–agentä½¿ç”¨ç›¸åŒçš„æ¨¡å‹
    
    def match_unmatched_parts(
        self,
        unmatched_parts: List[Dict],
        bom_data: List[Dict]
    ) -> List[Dict]:
        """
        ç”¨AIä¸€æ¬¡æ€§åŒ¹é…æ‰€æœ‰æœªåŒ¹é…çš„é›¶ä»¶

        Args:
            unmatched_parts: æœªåŒ¹é…çš„é›¶ä»¶åˆ—è¡¨
            bom_data: BOMè¡¨æ•°æ®

        Returns:
            AIåŒ¹é…ç»“æœåˆ—è¡¨
        """
        print(f"\n   ğŸ¤– AIå‘˜å·¥å¼€å§‹å·¥ä½œ...")
        print(f"      ğŸ“Š ä»–çœ‹åˆ°äº† {len(unmatched_parts)} ä¸ªæœªåŒ¹é…çš„3Dé›¶ä»¶")
        print(f"      ğŸ“‹ ä»–å‚è€ƒäº† {len(bom_data)} ä¸ªBOMé¡¹")
        print(f"      ğŸ¯ ä»–å‡†å¤‡ç”¨æ™ºèƒ½ç®—æ³•è¿›è¡ŒåŒ¹é…...")
        import sys
        sys.stdout.flush()

        # ä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰é›¶ä»¶
        all_results = self._match_all_at_once(unmatched_parts, bom_data)

        # ç»Ÿè®¡AIåŒ¹é…ç»“æœ
        matched_count = sum(1 for r in all_results if r.get('matched_bom_code'))
        unmatched_count = len(all_results) - matched_count
        match_rate = (matched_count / len(all_results) * 100) if all_results else 0

        # ç½®ä¿¡åº¦ç»Ÿè®¡
        high_confidence_count = sum(1 for r in all_results if r.get('confidence', 0) >= 0.85)
        medium_confidence_count = sum(1 for r in all_results if 0.6 <= r.get('confidence', 0) < 0.85)
        low_confidence_count = sum(1 for r in all_results if 0 < r.get('confidence', 0) < 0.6)

        print(f"\n" + "="*80)
        print(f"ğŸ¤– AIåŒ¹é…ç»“æœç»Ÿè®¡")
        print(f"="*80)
        print(f"ğŸ“Š æ€»é›¶ä»¶æ•°: {len(all_results)}")
        print(f"âœ… æˆåŠŸåŒ¹é…: {matched_count} ({match_rate:.1f}%)")
        print(f"âŒ æœªåŒ¹é…: {unmatched_count}")
        print(f"\nğŸ“ˆ ç½®ä¿¡åº¦åˆ†å¸ƒ:")
        print(f"   ğŸŸ¢ é«˜ç½®ä¿¡åº¦ (â‰¥0.85): {high_confidence_count}")
        print(f"   ğŸŸ¡ ä¸­ç½®ä¿¡åº¦ (0.6-0.85): {medium_confidence_count}")
        print(f"   ğŸ”´ ä½ç½®ä¿¡åº¦ (<0.6): {low_confidence_count}")

        if match_rate >= 95:
            print(f"\nğŸ‰ AIåŒ¹é…ç‡è¾¾åˆ° {match_rate:.1f}%ï¼Œè¡¨ç°ä¼˜ç§€ï¼")
        elif match_rate >= 80:
            print(f"\nğŸ‘ AIåŒ¹é…ç‡ {match_rate:.1f}%ï¼Œè¡¨ç°è‰¯å¥½")
        else:
            print(f"\nâš ï¸  AIåŒ¹é…ç‡ {match_rate:.1f}%ï¼Œéœ€è¦ä¼˜åŒ–æç¤ºè¯")
        print(f"="*80)

        import sys
        sys.stdout.flush()

        return all_results
    
    def _match_all_at_once(self, parts: List[Dict], bom_data: List[Dict]) -> List[Dict]:
        """
        ä¸€æ¬¡æ€§åŒ¹é…æ‰€æœ‰é›¶ä»¶

        Args:
            parts: æœªåŒ¹é…çš„3Dé›¶ä»¶åˆ—è¡¨
            bom_data: æœªåŒ¹é…çš„BOMåˆ—è¡¨ï¼ˆå·²ç»åœ¨è°ƒç”¨æ–¹è®¡ç®—å¥½äº†ï¼‰
        """

        print(f"      ğŸ“ ä»–æ­£åœ¨å‡†å¤‡åˆ†æèµ„æ–™...")
        import sys
        sys.stdout.flush()

        # âœ… bom_dataå·²ç»æ˜¯æœªåŒ¹é…çš„BOMäº†ï¼Œä¸éœ€è¦å†æ¬¡è®¡ç®—
        unmatched_bom = bom_data

        print(f"      ğŸ“Š ä»–å‘ç°è¿˜æœ‰ {len(unmatched_bom)} ä¸ªBOMæœªåŒ¹é…")
        sys.stdout.flush()

        # ä½¿ç”¨æç¤ºè¯æ–‡ä»¶æ„å»ºprompt
        system_prompt, user_query = build_ai_matching_prompt(parts, unmatched_bom)

        print(f"      ğŸ¤– ä»–å¼€å§‹è°ƒç”¨Gemini 2.5 Flashè¿›è¡Œæ·±åº¦åˆ†æ...")
        print(f"      â±ï¸  è¯·ç¨å€™ï¼ŒGeminié€Ÿåº¦å¾ˆå¿«...")
        sys.stdout.flush()

        # è°ƒç”¨AI
        try:
            import time
            start_time = time.time()

            response = self.client.chat.completions.create(
                model=self.model,  # ä½¿ç”¨Gemini 2.5 Flash
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_query}
                ],
                temperature=0.4,  # âœ… æé«˜åˆ°0.4ï¼Œä½¿ç”¨COTæ¨ç†ï¼Œè¿½æ±‚100%åŒ¹é…ç‡
                # âœ… ä¸é™åˆ¶max_tokensï¼ŒGemini 2.5 Flashæ”¯æŒ65.5Kè¾“å‡ºï¼ˆCOTéœ€è¦æ›´å¤štokenï¼‰
                stream=False,
                timeout=60
            )

            elapsed = time.time() - start_time
            result_text = response.choices[0].message.content

            print(f"      ğŸ“Š AIå¤§è„‘è¿”å›äº†åˆ†æç»“æœ ({len(result_text)} å­—ç¬¦, è€—æ—¶: {elapsed:.1f}ç§’)")
            import sys
            sys.stdout.flush()

            # è°ƒè¯•ï¼šä¿å­˜AIåŸå§‹å“åº”
            debug_file = f"debug_output/ai_matching_response_{int(time.time())}.txt"
            os.makedirs("debug_output", exist_ok=True)
            with open(debug_file, 'w', encoding='utf-8') as f:
                f.write(result_text)
            print(f"      ğŸ’¾ AIå“åº”å·²ä¿å­˜åˆ°: {debug_file}")

            # è§£æJSON
            ai_results = self._parse_response(result_text)

            if not ai_results:
                print(f"   âš ï¸  JSONè§£æå¤±è´¥ï¼Œè¿”å›ç©ºç»“æœ")
                return self._create_empty_results(parts)

            # å°†AIç»“æœæ˜ å°„å›åŸå§‹é›¶ä»¶
            # AIè¿”å›æ ¼å¼ï¼š{"node_name": "...", "geometry_name": "...", "bom_code": "...", "confidence": 0.85, "reasoning": "..."}
            results = []
            for part in parts:
                # æŸ¥æ‰¾å¯¹åº”çš„AIç»“æœï¼ˆé€šè¿‡node_nameæˆ–geometry_nameåŒ¹é…ï¼‰
                ai_result = None
                part_node_name = part.get('node_name', '')
                part_geometry = part.get('geometry_name', '')

                for ar in ai_results:
                    # ä¼˜å…ˆé€šè¿‡node_nameåŒ¹é…
                    if ar.get('node_name') == part_node_name:
                        ai_result = ar
                        break
                    # å¤‡ç”¨ï¼šé€šè¿‡geometry_nameåŒ¹é…
                    elif ar.get('geometry_name') == part_geometry:
                        ai_result = ar
                        break

                if ai_result:
                    results.append({
                        'geometry_name': part.get('geometry_name'),
                        'node_name': part.get('node_name'),
                        'matched_bom_code': ai_result.get('bom_code'),  # AIè¿”å›çš„æ˜¯bom_code
                        'confidence': ai_result.get('confidence', 0.0),
                        'reason': ai_result.get('reasoning', '')  # AIè¿”å›çš„æ˜¯reasoning
                    })
                else:
                    # å¦‚æœæ²¡æ‰¾åˆ°å¯¹åº”ç»“æœï¼Œè¿”å›ç©ºåŒ¹é…
                    results.append({
                        'geometry_name': part.get('geometry_name'),
                        'node_name': part.get('node_name'),
                        'matched_bom_code': None,
                        'confidence': 0.0,
                        'reason': 'AIæœªè¿”å›åŒ¹é…ç»“æœ'
                    })

            return results

        except Exception as e:
            print(f"   âŒ AIåŒ¹é…å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return self._create_empty_results(parts)

    def _create_empty_results(self, parts: List[Dict]) -> List[Dict]:
        """åˆ›å»ºç©ºçš„åŒ¹é…ç»“æœ"""
        return [
            {
                "geometry_name": p.get('geometry_name'),
                "node_name": p.get('node_name'),
                "matched_bom_code": None,
                "confidence": 0.0,
                "reason": "AIåŒ¹é…å¤±è´¥"
            }
            for p in parts
        ]
    
    def _build_prompt(self, parts: List[Dict], bom_data: List[Dict]) -> str:
        """æ„å»ºAIåŒ¹é…çš„prompt"""
        
        # é™åˆ¶BOMè¡¨å¤§å°ï¼ˆåªå‘é€å‰100é¡¹ï¼‰
        bom_sample = bom_data[:100] if len(bom_data) > 100 else bom_data
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªBOM-3Dé›¶ä»¶åŒ¹é…ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†3Dæ¨¡å‹ä¸­çš„é›¶ä»¶åç§°ä¸BOMè¡¨ä¸­çš„é¡¹ç›®è¿›è¡ŒåŒ¹é…ã€‚

## èƒŒæ™¯
- 3Dé›¶ä»¶åç§°å¯èƒ½æœ‰ç¼–ç é—®é¢˜ï¼ˆä¹±ç ï¼‰ï¼Œä½†ä½ å¯ä»¥é€šè¿‡äº§å“ä»£å·ã€è§„æ ¼ã€å…³é”®è¯ç­‰çº¿ç´¢è¿›è¡ŒåŒ¹é…
- BOMè¡¨åŒ…å«ï¼šä»£å·ï¼ˆcodeï¼‰ã€äº§å“ä»£å·ï¼ˆproduct_codeï¼‰ã€åç§°ï¼ˆnameï¼‰ç­‰ä¿¡æ¯
- åŒ¹é…ä¾æ®ï¼šäº§å“ä»£å·ï¼ˆä¼˜å…ˆï¼‰ã€è§„æ ¼ï¼ˆå¦‚M16ã€Ï†40ç­‰ï¼‰ã€é›¶ä»¶ç±»å‹ï¼ˆèºæ “ã€å«åœˆã€æ–¹å½¢æ¿ç­‰ï¼‰

## BOMè¡¨ï¼ˆ{len(bom_data)}é¡¹ï¼Œæ˜¾ç¤ºå‰{len(bom_sample)}é¡¹ï¼‰
```json
{json.dumps(bom_sample, ensure_ascii=False, indent=2)[:2000]}
...
```

## æœªåŒ¹é…çš„3Dé›¶ä»¶ï¼ˆ{len(parts)}ä¸ªï¼‰
```json
{json.dumps([{'fixed_name': p['fixed_name'], 'geometry_name': p['geometry_name']} for p in parts], ensure_ascii=False, indent=2)}
```

## åŒ¹é…è§„åˆ™
1. **ä¼˜å…ˆåŒ¹é…äº§å“ä»£å·**ï¼šå¦‚æœ3Dé›¶ä»¶åç§°ä¸­åŒ…å«äº§å“ä»£å·ï¼ˆå¦‚T-SPV1830-EURO-09ï¼‰ï¼Œä¼˜å…ˆåŒ¹é…
2. **è§„æ ¼åŒ¹é…**ï¼šå¯¹äºæ ‡å‡†ä»¶ï¼ˆèºæ “ã€å«åœˆç­‰ï¼‰ï¼Œé€šè¿‡è§„æ ¼ï¼ˆM16ã€Ï†40ç­‰ï¼‰åŒ¹é…
3. **å…³é”®è¯åŒ¹é…**ï¼šé€šè¿‡é›¶ä»¶ç±»å‹å…³é”®è¯ï¼ˆæ–¹å½¢æ¿ã€å«åœˆã€èºæ “ç­‰ï¼‰è¾…åŠ©åŒ¹é…
4. **æ— æ³•åŒ¹é…**ï¼šå¦‚æœBOMè¡¨ä¸­ç¡®å®æ²¡æœ‰å¯¹åº”é¡¹ï¼Œè¿”å›null

## è¾“å‡ºæ ¼å¼
è¿”å›JSONæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
- geometry_name: 3Dé›¶ä»¶çš„åŸå§‹åç§°ï¼ˆå¿…é¡»ä¸è¾“å…¥å®Œå…¨ä¸€è‡´ï¼‰
- bom_code: åŒ¹é…åˆ°çš„BOMä»£å·ï¼ˆå¦‚"01.09.2556"ï¼‰ï¼Œå¦‚æœæ— æ³•åŒ¹é…åˆ™ä¸ºnull
- confidence: åŒ¹é…ç½®ä¿¡åº¦ï¼ˆ0-1ï¼‰
- reasoning: åŒ¹é…ç†ç”±ï¼ˆç®€çŸ­è¯´æ˜ï¼‰

è¯·åªè¿”å›JSONæ•°ç»„ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚

ç¤ºä¾‹è¾“å‡ºï¼š
[
  {
    "geometry_name": "T-SPV1830-EURO-09-Q235",
    "bom_code": "01.09.2556",
    "confidence": 0.95,
    "reasoning": "äº§å“ä»£å·å®Œå…¨åŒ¹é…"
  },
  {
    "geometry_name": "M16x60-GB/T5782-2000",
    "bom_code": "02.03.0088",
    "confidence": 0.85,
    "reasoning": "è§„æ ¼M16åŒ¹é…"
  }
]
"""
        return prompt
    
    def _parse_response(self, response_text: str) -> List[Dict]:
        """è§£æAIå“åº”ï¼ˆå‚è€ƒdual_channel_parserçš„æˆç†Ÿæ–¹æ¡ˆï¼‰"""

        # ç§»é™¤markdownä»£ç å—æ ‡è®°ï¼ˆå‚è€ƒdual_channel_parserï¼‰
        content = response_text.strip()

        if content.startswith('```json'):
            content = content[7:]  # ç§»é™¤ ```json

        if content.startswith('```'):
            content = content[3:]  # ç§»é™¤ ```

        if content.endswith('```'):
            content = content[:-3]  # ç§»é™¤ç»“å°¾çš„ ```

        content = content.strip()

        # æŸ¥æ‰¾JSONçš„å¼€å§‹å’Œç»“æŸ
        json_start = content.find('{')
        json_end = content.rfind('}') + 1

        if json_start >= 0 and json_end > json_start:
            json_str = content[json_start:json_end]

            # âœ… è‡ªåŠ¨ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é”™è¯¯
            # 1. ç§»é™¤æ•°ç»„/å¯¹è±¡æœ€åä¸€ä¸ªå…ƒç´ åçš„é€—å·ï¼ˆå¦‚ },\n] æˆ– },\n}ï¼‰
            json_str = re.sub(r',(\s*[\]}])', r'\1', json_str)

            # 2. ç§»é™¤æ§åˆ¶å­—ç¬¦
            json_str = ''.join(char for char in json_str if ord(char) >= 32 or char in '\n\r\t')

            # å°è¯•è§£æJSON
            try:
                parsed_result = json.loads(json_str)
                print(f"      âœ… JSONè§£ææˆåŠŸ")

                # å¦‚æœè¿”å›çš„æ˜¯å¯¹è±¡ï¼Œæå–ai_matched_pairså­—æ®µ
                if isinstance(parsed_result, dict):
                    if 'ai_matched_pairs' in parsed_result:
                        return parsed_result['ai_matched_pairs']
                    else:
                        print(f"      âš ï¸  JSONæ ¼å¼é”™è¯¯ï¼šç¼ºå°‘'ai_matched_pairs'å­—æ®µ")
                        return []
                # å¦‚æœç›´æ¥è¿”å›æ•°ç»„
                elif isinstance(parsed_result, list):
                    return parsed_result
                else:
                    print(f"      âš ï¸  JSONæ ¼å¼é”™è¯¯ï¼šæœŸæœ›å¯¹è±¡æˆ–æ•°ç»„ï¼Œå¾—åˆ° {type(parsed_result)}")
                    return []

            except json.JSONDecodeError as e:
                error_msg = f"JSONè§£æå¤±è´¥: line {e.lineno} column {e.colno} (char {e.pos})"
                print(f"      âš ï¸  {error_msg}")
                return []
            except Exception as e:
                print(f"      âš ï¸  è§£æé”™è¯¯: {e}")
                return []
        else:
            print(f"      âš ï¸  æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONæ•°æ®")
            return []
    
    def apply_ai_matches(
        self,
        cleaned_parts: List[Dict],
        ai_matches: List[Dict],
        min_confidence: float = 0.8
    ) -> List[Dict]:
        """
        å°†AIåŒ¹é…ç»“æœåº”ç”¨åˆ°é›¶ä»¶åˆ—è¡¨
        
        Args:
            cleaned_parts: æ¸…æ´—åçš„é›¶ä»¶åˆ—è¡¨
            ai_matches: AIåŒ¹é…ç»“æœ
            min_confidence: æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼
            
        Returns:
            æ›´æ–°åçš„é›¶ä»¶åˆ—è¡¨
        """
        print(f"\nğŸ”§ åº”ç”¨AIåŒ¹é…ç»“æœ...")
        
        # åˆ›å»ºgeometry_nameåˆ°AIåŒ¹é…çš„æ˜ å°„
        ai_match_map = {
            m['geometry_name']: m
            for m in ai_matches
            if m.get('matched_bom_code') and m.get('confidence', 0) >= min_confidence
        }
        
        # åº”ç”¨AIåŒ¹é…
        updated_count = 0
        for part in cleaned_parts:
            # åªæ›´æ–°æœªåŒ¹é…çš„é›¶ä»¶
            if not part.get('bom_code'):
                geometry_name = part['geometry_name']
                if geometry_name in ai_match_map:
                    ai_match = ai_match_map[geometry_name]
                    part['bom_code'] = ai_match['matched_bom_code']
                    part['match_method'] = f"AIåŒ¹é…(ç½®ä¿¡åº¦{ai_match['confidence']:.2f})"
                    part['confidence'] = ai_match['confidence']
                    part['ai_reason'] = ai_match.get('reason', '')
                    updated_count += 1
        
        print(f"   æ›´æ–°äº† {updated_count} ä¸ªé›¶ä»¶çš„åŒ¹é…ç»“æœ")
        
        return cleaned_parts

