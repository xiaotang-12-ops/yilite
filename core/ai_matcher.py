"""
AIæ™ºèƒ½åŒ¹é…å™¨
ç”¨äºå¤„ç†ä»£ç åŒ¹é…å¤±è´¥çš„é›¶ä»¶
"""

import json
import re
from typing import List, Dict, Optional
from openai import OpenAI
import sys
import os
from utils.time_utils import beijing_now

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥æç¤ºè¯
from prompts.agent_2_bom_3d_matching import (
    build_ai_matching_prompt,
    AI_MATCHING_SYSTEM_PROMPT
)


class AIBOMMatcher:
    """AIæ™ºèƒ½BOMåŒ¹é…å™¨ï¼ˆä½¿ç”¨Gemini 2.5 Flashï¼‰"""

    def __init__(self, api_key: Optional[str] = None, task_id: Optional[str] = None):
        # ä½¿ç”¨Gemini 2.5 Flashï¼ˆé€šè¿‡OpenRouterï¼‰
        self.api_key = api_key or os.getenv("OPENROUTER_API_KEY")
        if not self.api_key:
            raise ValueError("éœ€è¦è®¾ç½®OPENROUTER_API_KEYç¯å¢ƒå˜é‡æˆ–ä¼ å…¥api_keyå‚æ•°")

        self.client = OpenAI(
            api_key=self.api_key,
            base_url="https://openrouter.ai/api/v1"
        )
        self.model = "google/gemini-2.5-flash-preview-09-2025"  # å’Œå…¶ä»–agentä½¿ç”¨ç›¸åŒçš„æ¨¡å‹
        # è®°å½•ä»»åŠ¡IDç”¨äºè°ƒè¯•æ–‡ä»¶å‘½å
        self.task_id = task_id or os.getenv("TASK_ID", "unknown_task")
        # æ‰¹å¤„ç†å‚æ•°ï¼ˆæœªåŒ¹é…é›¶ä»¶è¶…è¿‡é˜ˆå€¼æ—¶åˆ†æ‰¹ï¼Œä»¥é˜²å“åº”æˆªæ–­ï¼‰
        self.batch_threshold = 200  # è¶…è¿‡è¿™ä¸ªæ•°é‡çš„æœªåŒ¹é…3Dé›¶ä»¶å°±åˆ†æ‰¹
        self.batch_size = 100       # å•æ‰¹ä¸Šé™
        self.min_batch_size = 20    # æˆªæ–­é‡è¯•æ—¶çš„æœ€å°æ‰¹å¤§å°ï¼ˆé¿å…æ— é™æ‹†åˆ†ï¼‰
    
    def match_unmatched_parts(
        self,
        unmatched_parts: List[Dict],
        bom_data: List[Dict]
    ) -> List[Dict]:
        """
        ç”¨AIä¸€æ¬¡æ€§åŒ¹é…æ‰€æœ‰æœªåŒ¹é…çš„é›¶ä»¶

        Args:
            unmatched_parts: æœªåŒ¹é…çš„é›¶ä»¶åˆ—è¡¨
            bom_data: BOMè¡¨æ•°æ®

        Returns:
            AIåŒ¹é…ç»“æœåˆ—è¡¨
        """
        print(f"\n   ğŸ¤– AIå‘˜å·¥å¼€å§‹å·¥ä½œ...")
        print(f"      ğŸ“Š ä»–çœ‹åˆ°äº† {len(unmatched_parts)} ä¸ªæœªåŒ¹é…çš„3Dé›¶ä»¶")
        print(f"      ğŸ“‹ ä»–å‚è€ƒäº† {len(bom_data)} ä¸ªBOMé¡¹")
        print(f"      ğŸ¯ ä»–å‡†å¤‡ç”¨æ™ºèƒ½ç®—æ³•è¿›è¡ŒåŒ¹é…...")
        import sys
        sys.stdout.flush()

        # ç»Ÿä¸€çš„è°ƒè¯•æ–‡ä»¶æ ‡è¯†
        ts_str = beijing_now().strftime("%Y%m%d_%H%M%S")
        safe_task = re.sub(r"[^A-Za-z0-9._-]+", "_", str(self.task_id)) or "unknown_task"

        # æ ¹æ®æ•°é‡å†³å®šæ˜¯å¦åˆ†æ‰¹ï¼Œä»¥é¿å…å¤§å“åº”è¢«æˆªæ–­
        if len(unmatched_parts) > self.batch_threshold:
            print(f"      ğŸ“¦ æœªåŒ¹é…é›¶ä»¶è¶…è¿‡ {self.batch_threshold} ä¸ªï¼ŒæŒ‰æ‰¹æ¬¡å¤„ç†ï¼ˆå•æ‰¹ {self.batch_size} ä¸ªï¼‰...")
            sys.stdout.flush()
            all_results = self._match_in_batches(unmatched_parts, bom_data, safe_task, ts_str)
        else:
            all_results = self._match_all_at_once(unmatched_parts, bom_data, safe_task, ts_str, allow_split=True)

        # ç»Ÿè®¡AIåŒ¹é…ç»“æœ
        matched_count = sum(1 for r in all_results if r.get('matched_bom_code'))
        unmatched_count = len(all_results) - matched_count
        match_rate = (matched_count / len(all_results) * 100) if all_results else 0

        # ç½®ä¿¡åº¦ç»Ÿè®¡
        high_confidence_count = sum(1 for r in all_results if r.get('confidence', 0) >= 0.85)
        medium_confidence_count = sum(1 for r in all_results if 0.6 <= r.get('confidence', 0) < 0.85)
        low_confidence_count = sum(1 for r in all_results if 0 < r.get('confidence', 0) < 0.6)

        print(f"\n" + "="*80)
        print(f"ğŸ¤– AIåŒ¹é…ç»“æœç»Ÿè®¡")
        print(f"="*80)
        print(f"ğŸ“Š æ€»é›¶ä»¶æ•°: {len(all_results)}")
        print(f"âœ… æˆåŠŸåŒ¹é…: {matched_count} ({match_rate:.1f}%)")
        print(f"âŒ æœªåŒ¹é…: {unmatched_count}")
        print(f"\nğŸ“ˆ ç½®ä¿¡åº¦åˆ†å¸ƒ:")
        print(f"   ğŸŸ¢ é«˜ç½®ä¿¡åº¦ (â‰¥0.85): {high_confidence_count}")
        print(f"   ğŸŸ¡ ä¸­ç½®ä¿¡åº¦ (0.6-0.85): {medium_confidence_count}")
        print(f"   ğŸ”´ ä½ç½®ä¿¡åº¦ (<0.6): {low_confidence_count}")

        if match_rate >= 95:
            print(f"\nğŸ‰ AIåŒ¹é…ç‡è¾¾åˆ° {match_rate:.1f}%ï¼Œè¡¨ç°ä¼˜ç§€ï¼")
        elif match_rate >= 80:
            print(f"\nğŸ‘ AIåŒ¹é…ç‡ {match_rate:.1f}%ï¼Œè¡¨ç°è‰¯å¥½")
        else:
            print(f"\nâš ï¸  AIåŒ¹é…ç‡ {match_rate:.1f}%ï¼Œéœ€è¦ä¼˜åŒ–æç¤ºè¯")
        print(f"="*80)

        import sys
        sys.stdout.flush()

        return all_results
    
    def _match_all_at_once(
        self,
        parts: List[Dict],
        bom_data: List[Dict],
        safe_task: str,
        ts_str: str,
        batch_label: Optional[str] = None,
        allow_split: bool = False
    ) -> List[Dict]:
        """
        åŒ¹é…ä¸€æ‰¹é›¶ä»¶ï¼›å¯åœ¨æ£€æµ‹åˆ°æˆªæ–­æ—¶æŒ‰éœ€æ‹†åˆ†

        Args:
            parts: æœªåŒ¹é…çš„3Dé›¶ä»¶åˆ—è¡¨
            bom_data: æœªåŒ¹é…çš„BOMåˆ—è¡¨ï¼ˆå·²ç»åœ¨è°ƒç”¨æ–¹è®¡ç®—å¥½äº†ï¼‰
            safe_task: ä»»åŠ¡åï¼ˆç”¨äºè°ƒè¯•æ–‡ä»¶ï¼‰
            ts_str: æ—¶é—´æˆ³ï¼ˆç”¨äºè°ƒè¯•æ–‡ä»¶ï¼‰
            batch_label: æ‰¹æ¬¡æ ‡è¯†ï¼Œç”¨äºè°ƒè¯•æ–‡ä»¶å‘½å
            allow_split: æˆªæ–­æ—¶æ˜¯å¦ç»§ç»­æ‹†åˆ†å½“å‰æ‰¹
        """

        print(f"      ğŸ“ ä»–æ­£åœ¨å‡†å¤‡åˆ†æèµ„æ–™... (æ‰¹æ¬¡: {batch_label or 'å…¨é‡'}, æ•°é‡: {len(parts)})")
        import sys
        sys.stdout.flush()

        # âœ… bom_dataå·²ç»æ˜¯æœªåŒ¹é…çš„BOMäº†ï¼Œä¸éœ€è¦å†æ¬¡è®¡ç®—
        unmatched_bom = bom_data

        print(f"      ğŸ“Š ä»–å‘ç°è¿˜æœ‰ {len(unmatched_bom)} ä¸ªBOMæœªåŒ¹é…")
        sys.stdout.flush()

        # ä½¿ç”¨æç¤ºè¯æ–‡ä»¶æ„å»ºprompt
        system_prompt, user_query = build_ai_matching_prompt(parts, unmatched_bom)

        print(f"      ğŸ¤– ä»–å¼€å§‹è°ƒç”¨Gemini 2.5 Flashè¿›è¡Œæ·±åº¦åˆ†æ...")
        print(f"      â±ï¸  è¯·ç¨å€™ï¼ŒGeminié€Ÿåº¦å¾ˆå¿«...")
        sys.stdout.flush()

        # è°ƒç”¨AIï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        max_retries = 3
        retry_delay = 5  # ç§’

        try:
            import time
            start_time = time.time()

            last_error = None
            for attempt in range(max_retries):
                try:
                    if attempt > 0:
                        print(f"      ğŸ”„ ç¬¬ {attempt + 1} æ¬¡é‡è¯•...")
                        time.sleep(retry_delay)

                    response = self.client.chat.completions.create(
                        model=self.model,  # ä½¿ç”¨Gemini 2.5 Flash
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_query}
                        ],
                        temperature=0.4,  # âœ… æé«˜åˆ°0.4ï¼Œä½¿ç”¨COTæ¨ç†ï¼Œè¿½æ±‚100%åŒ¹é…ç‡
                        # âœ… ä¸é™åˆ¶max_tokensï¼ŒGemini 2.5 Flashæ”¯æŒ65.5Kè¾“å‡ºï¼ˆCOTéœ€è¦æ›´å¤štokenï¼‰
                        stream=False,
                        timeout=120  # âœ… å¢åŠ è¶…æ—¶æ—¶é—´åˆ°120ç§’
                    )
                    break  # æˆåŠŸåˆ™è·³å‡ºé‡è¯•å¾ªç¯
                except Exception as retry_error:
                    last_error = retry_error
                    print(f"      âš ï¸  è¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {retry_error}")
                    if attempt == max_retries - 1:
                        raise last_error  # æœ€åä¸€æ¬¡é‡è¯•ä¹Ÿå¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸

            elapsed = time.time() - start_time
            choice = response.choices[0]
            result_text = choice.message.content
            finish_reason = getattr(choice, "finish_reason", None)

            print(f"      ğŸ“Š AIå¤§è„‘è¿”å›äº†åˆ†æç»“æœ ({len(result_text)} å­—ç¬¦, è€—æ—¶: {elapsed:.1f}ç§’, finish_reason={finish_reason})")
            import sys
            sys.stdout.flush()

            # è°ƒè¯•ï¼šä¿å­˜AIåŸå§‹å“åº”
            debug_file = f"debug_output/ai_matching_response_{safe_task}_{ts_str}.txt"
            if batch_label:
                debug_file = debug_file.replace(".txt", f"_part{batch_label}.txt")
            os.makedirs("debug_output", exist_ok=True)
            with open(debug_file, 'w', encoding='utf-8') as f:
                f.write(result_text)
            print(f"      ğŸ’¾ AIå“åº”å·²ä¿å­˜åˆ°: {debug_file}")

            # è§£æJSON
            ai_results = self._parse_response(result_text)

            truncated = False
            if finish_reason and finish_reason != "stop":
                truncated = True
            if not ai_results:
                truncated = True
            elif len(ai_results) < len(parts) and finish_reason and finish_reason != "stop":
                truncated = True

            if truncated and allow_split and len(parts) > self.min_batch_size:
                print(f"      âš ï¸  æ£€æµ‹åˆ°å“åº”å¯èƒ½è¢«æˆªæ–­ï¼Œæ‹†åˆ†æœ¬æ‰¹ç»§ç»­å¤„ç†ï¼ˆæ‰¹æ¬¡: {batch_label or 'å…¨é‡'}ï¼‰")
                mid = len(parts) // 2 or 1
                left = parts[:mid]
                right = parts[mid:]
                left_results = self._match_all_at_once(left, bom_data, safe_task, ts_str, f"{batch_label or '1'}-a", allow_split=True)
                right_results = self._match_all_at_once(right, bom_data, safe_task, ts_str, f"{batch_label or '1'}-b", allow_split=True)
                return left_results + right_results

            if not ai_results:
                print(f"   âš ï¸  JSONè§£æå¤±è´¥ï¼Œè¿”å›ç©ºç»“æœ")
                return self._create_empty_results(parts)

            return self._map_ai_results(parts, ai_results)

        except Exception as e:
            print(f"   âŒ AIåŒ¹é…å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

            # âœ… ä¿å­˜å¤±è´¥ä¿¡æ¯åˆ°è°ƒè¯•æ–‡ä»¶
            try:
                batch_suffix = f"_part{batch_label}" if batch_label else ""
                error_file = f"debug_output/ai_matching_ERROR_{safe_task}_{ts_str}{batch_suffix}.txt"
                os.makedirs("debug_output", exist_ok=True)
                with open(error_file, "w", encoding="utf-8") as f:
                    f.write(f"=== AIåŒ¹é…å¤±è´¥ ===\n")
                    f.write(f"æ—¶é—´: {ts_str}\n")
                    f.write(f"æ‰¹æ¬¡: {batch_label or 'å…¨é‡'}\n")
                    f.write(f"é›¶ä»¶æ•°: {len(parts)}\n")
                    f.write(f"BOMæ•°: {len(bom_data)}\n")
                    f.write(f"\n=== é”™è¯¯ä¿¡æ¯ ===\n")
                    f.write(f"{type(e).__name__}: {e}\n")
                    f.write(f"\n=== å †æ ˆè·Ÿè¸ª ===\n")
                    f.write(traceback.format_exc())
                    f.write(f"\n=== é›¶ä»¶åˆ—è¡¨ ===\n")
                    for p in parts[:10]:  # åªè®°å½•å‰10ä¸ª
                        f.write(f"  - {p.get('node_name', 'N/A')}: {p.get('geometry_name', 'N/A')[:50]}\n")
                    if len(parts) > 10:
                        f.write(f"  ... è¿˜æœ‰ {len(parts) - 10} ä¸ªé›¶ä»¶\n")
                print(f"   ğŸ“ é”™è¯¯ä¿¡æ¯å·²ä¿å­˜åˆ°: {error_file}")
            except Exception as save_error:
                print(f"   âš ï¸  ä¿å­˜é”™è¯¯ä¿¡æ¯å¤±è´¥: {save_error}")

            return self._create_empty_results(parts)

    def _match_in_batches(
        self,
        parts: List[Dict],
        bom_data: List[Dict],
        safe_task: str,
        ts_str: str
    ) -> List[Dict]:
        """åˆ†æ‰¹å¤„ç†æœªåŒ¹é…é›¶ä»¶ï¼Œé˜²æ­¢å•æ¬¡å“åº”è¿‡é•¿è¢«æˆªæ–­"""
        results: List[Dict] = []
        batch_no = 0
        total_parts = len(parts)
        for start in range(0, total_parts, self.batch_size):
            batch_no += 1
            end = min(start + self.batch_size, total_parts)
            batch_parts = parts[start:end]
            print(f"\n   ğŸ“¦ æ­£åœ¨å¤„ç†æ‰¹æ¬¡ {batch_no}: {len(batch_parts)} ä¸ªé›¶ä»¶ï¼ˆèŒƒå›´ {start+1}-{end}/{total_parts}ï¼‰")
            batch_results = self._match_all_at_once(
                batch_parts,
                bom_data,
                safe_task,
                ts_str,
                batch_label=str(batch_no),
                allow_split=True
            )
            results.extend(batch_results)
        return results

    def _map_ai_results(self, parts: List[Dict], ai_results: List[Dict]) -> List[Dict]:
        """
        å°†AIç»“æœæ˜ å°„å›åŸå§‹é›¶ä»¶

        AIè¿”å›æ ¼å¼ï¼š{"node_name": "...", "geometry_name": "...", "bom_code": "...", "confidence": 0.85, "reasoning": "..."}
        """
        results = []
        for part in parts:
            ai_result = None
            part_node_name = part.get('node_name', '')
            part_geometry = part.get('geometry_name', '')

            for ar in ai_results:
                # ä¼˜å…ˆé€šè¿‡node_nameåŒ¹é…
                if ar.get('node_name') == part_node_name:
                    ai_result = ar
                    break
                # å¤‡ç”¨ï¼šé€šè¿‡geometry_nameåŒ¹é…
                elif ar.get('geometry_name') == part_geometry:
                    ai_result = ar
                    break

            if ai_result:
                results.append({
                    'geometry_name': part.get('geometry_name'),
                    'node_name': part.get('node_name'),
                    'matched_bom_code': ai_result.get('bom_code'),  # AIè¿”å›çš„æ˜¯bom_code
                    'confidence': ai_result.get('confidence', 0.0),
                    'reason': ai_result.get('reasoning', '')  # AIè¿”å›çš„æ˜¯reasoning
                })
            else:
                # å¦‚æœæ²¡æ‰¾åˆ°å¯¹åº”ç»“æœï¼Œè¿”å›ç©ºåŒ¹é…
                results.append({
                    'geometry_name': part.get('geometry_name'),
                    'node_name': part.get('node_name'),
                    'matched_bom_code': None,
                    'confidence': 0.0,
                    'reason': 'AIæœªè¿”å›åŒ¹é…ç»“æœ'
                })

        return results

    def _create_empty_results(self, parts: List[Dict]) -> List[Dict]:
        """åˆ›å»ºç©ºçš„åŒ¹é…ç»“æœ"""
        return [
            {
                "geometry_name": p.get('geometry_name'),
                "node_name": p.get('node_name'),
                "matched_bom_code": None,
                "confidence": 0.0,
                "reason": "AIåŒ¹é…å¤±è´¥"
            }
            for p in parts
        ]
    
    def _build_prompt(self, parts: List[Dict], bom_data: List[Dict]) -> str:
        """æ„å»ºAIåŒ¹é…çš„prompt"""
        
        # é™åˆ¶BOMè¡¨å¤§å°ï¼ˆåªå‘é€å‰100é¡¹ï¼‰
        bom_sample = bom_data[:100] if len(bom_data) > 100 else bom_data
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªBOM-3Dé›¶ä»¶åŒ¹é…ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†3Dæ¨¡å‹ä¸­çš„é›¶ä»¶åç§°ä¸BOMè¡¨ä¸­çš„é¡¹ç›®è¿›è¡ŒåŒ¹é…ã€‚

## èƒŒæ™¯
- 3Dé›¶ä»¶åç§°å¯èƒ½æœ‰ç¼–ç é—®é¢˜ï¼ˆä¹±ç ï¼‰ï¼Œä½†ä½ å¯ä»¥é€šè¿‡äº§å“ä»£å·ã€è§„æ ¼ã€å…³é”®è¯ç­‰çº¿ç´¢è¿›è¡ŒåŒ¹é…
- BOMè¡¨åŒ…å«ï¼šä»£å·ï¼ˆcodeï¼‰ã€äº§å“ä»£å·ï¼ˆproduct_codeï¼‰ã€åç§°ï¼ˆnameï¼‰ç­‰ä¿¡æ¯
- åŒ¹é…ä¾æ®ï¼šäº§å“ä»£å·ï¼ˆä¼˜å…ˆï¼‰ã€è§„æ ¼ï¼ˆå¦‚M16ã€Ï†40ç­‰ï¼‰ã€é›¶ä»¶ç±»å‹ï¼ˆèºæ “ã€å«åœˆã€æ–¹å½¢æ¿ç­‰ï¼‰

## BOMè¡¨ï¼ˆ{len(bom_data)}é¡¹ï¼Œæ˜¾ç¤ºå‰{len(bom_sample)}é¡¹ï¼‰
```json
{json.dumps(bom_sample, ensure_ascii=False, indent=2)[:2000]}
...
```

## æœªåŒ¹é…çš„3Dé›¶ä»¶ï¼ˆ{len(parts)}ä¸ªï¼‰
```json
{json.dumps([{'fixed_name': p['fixed_name'], 'geometry_name': p['geometry_name']} for p in parts], ensure_ascii=False, indent=2)}
```

## åŒ¹é…è§„åˆ™
1. **ä¼˜å…ˆåŒ¹é…äº§å“ä»£å·**ï¼šå¦‚æœ3Dé›¶ä»¶åç§°ä¸­åŒ…å«äº§å“ä»£å·ï¼ˆå¦‚T-SPV1830-EURO-09ï¼‰ï¼Œä¼˜å…ˆåŒ¹é…
2. **è§„æ ¼åŒ¹é…**ï¼šå¯¹äºæ ‡å‡†ä»¶ï¼ˆèºæ “ã€å«åœˆç­‰ï¼‰ï¼Œé€šè¿‡è§„æ ¼ï¼ˆM16ã€Ï†40ç­‰ï¼‰åŒ¹é…
3. **å…³é”®è¯åŒ¹é…**ï¼šé€šè¿‡é›¶ä»¶ç±»å‹å…³é”®è¯ï¼ˆæ–¹å½¢æ¿ã€å«åœˆã€èºæ “ç­‰ï¼‰è¾…åŠ©åŒ¹é…
4. **æ— æ³•åŒ¹é…**ï¼šå¦‚æœBOMè¡¨ä¸­ç¡®å®æ²¡æœ‰å¯¹åº”é¡¹ï¼Œè¿”å›null

## è¾“å‡ºæ ¼å¼
è¿”å›JSONæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
- geometry_name: 3Dé›¶ä»¶çš„åŸå§‹åç§°ï¼ˆå¿…é¡»ä¸è¾“å…¥å®Œå…¨ä¸€è‡´ï¼‰
- bom_code: åŒ¹é…åˆ°çš„BOMä»£å·ï¼ˆå¦‚"01.09.2556"ï¼‰ï¼Œå¦‚æœæ— æ³•åŒ¹é…åˆ™ä¸ºnull
- confidence: åŒ¹é…ç½®ä¿¡åº¦ï¼ˆ0-1ï¼‰
- reasoning: åŒ¹é…ç†ç”±ï¼ˆç®€çŸ­è¯´æ˜ï¼‰

è¯·åªè¿”å›JSONæ•°ç»„ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚

ç¤ºä¾‹è¾“å‡ºï¼š
[
  {
    "geometry_name": "T-SPV1830-EURO-09-Q235",
    "bom_code": "01.09.2556",
    "confidence": 0.95,
    "reasoning": "äº§å“ä»£å·å®Œå…¨åŒ¹é…"
  },
  {
    "geometry_name": "M16x60-GB/T5782-2000",
    "bom_code": "02.03.0088",
    "confidence": 0.85,
    "reasoning": "è§„æ ¼M16åŒ¹é…"
  }
]
"""
        return prompt
    
    def _parse_response(self, response_text: str) -> List[Dict]:
        """è§£æAIå“åº”ï¼ˆå‚è€ƒdual_channel_parserçš„æˆç†Ÿæ–¹æ¡ˆï¼‰"""

        # ç§»é™¤markdownä»£ç å—æ ‡è®°ï¼ˆå‚è€ƒdual_channel_parserï¼‰
        content = response_text.strip()

        if content.startswith('```json'):
            content = content[7:]  # ç§»é™¤ ```json

        if content.startswith('```'):
            content = content[3:]  # ç§»é™¤ ```

        if content.endswith('```'):
            content = content[:-3]  # ç§»é™¤ç»“å°¾çš„ ```

        content = content.strip()

        # æŸ¥æ‰¾JSONçš„å¼€å§‹å’Œç»“æŸ
        json_start = content.find('{')
        json_end = content.rfind('}') + 1

        if json_start >= 0 and json_end > json_start:
            json_str = content[json_start:json_end]

            # âœ… è‡ªåŠ¨ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é”™è¯¯
            # 1. ç§»é™¤æ•°ç»„/å¯¹è±¡æœ€åä¸€ä¸ªå…ƒç´ åçš„é€—å·ï¼ˆå¦‚ },\n] æˆ– },\n}ï¼‰
            json_str = re.sub(r',(\s*[\]}])', r'\1', json_str)

            # 2. ç§»é™¤æ§åˆ¶å­—ç¬¦
            json_str = ''.join(char for char in json_str if ord(char) >= 32 or char in '\n\r\t')

            # å°è¯•è§£æJSON
            try:
                parsed_result = json.loads(json_str)
                print(f"      âœ… JSONè§£ææˆåŠŸ")

                # å¦‚æœè¿”å›çš„æ˜¯å¯¹è±¡ï¼Œæå–ai_matched_pairså­—æ®µ
                if isinstance(parsed_result, dict):
                    if 'ai_matched_pairs' in parsed_result:
                        return parsed_result['ai_matched_pairs']
                    else:
                        print(f"      âš ï¸  JSONæ ¼å¼é”™è¯¯ï¼šç¼ºå°‘'ai_matched_pairs'å­—æ®µ")
                        return []
                # å¦‚æœç›´æ¥è¿”å›æ•°ç»„
                elif isinstance(parsed_result, list):
                    return parsed_result
                else:
                    print(f"      âš ï¸  JSONæ ¼å¼é”™è¯¯ï¼šæœŸæœ›å¯¹è±¡æˆ–æ•°ç»„ï¼Œå¾—åˆ° {type(parsed_result)}")
                    return []

            except json.JSONDecodeError as e:
                error_msg = f"JSONè§£æå¤±è´¥: line {e.lineno} column {e.colno} (char {e.pos})"
                print(f"      âš ï¸  {error_msg}")
                return []
            except Exception as e:
                print(f"      âš ï¸  è§£æé”™è¯¯: {e}")
                return []
        else:
            print(f"      âš ï¸  æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONæ•°æ®")
            return []
    
    def apply_ai_matches(
        self,
        cleaned_parts: List[Dict],
        ai_matches: List[Dict],
        min_confidence: float = 0.8
    ) -> List[Dict]:
        """
        å°†AIåŒ¹é…ç»“æœåº”ç”¨åˆ°é›¶ä»¶åˆ—è¡¨
        
        Args:
            cleaned_parts: æ¸…æ´—åçš„é›¶ä»¶åˆ—è¡¨
            ai_matches: AIåŒ¹é…ç»“æœ
            min_confidence: æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼
            
        Returns:
            æ›´æ–°åçš„é›¶ä»¶åˆ—è¡¨
        """
        print(f"\nğŸ”§ åº”ç”¨AIåŒ¹é…ç»“æœ...")
        
        # åˆ›å»ºgeometry_nameåˆ°AIåŒ¹é…çš„æ˜ å°„
        ai_match_map = {
            m['geometry_name']: m
            for m in ai_matches
            if m.get('matched_bom_code') and m.get('confidence', 0) >= min_confidence
        }
        
        # åº”ç”¨AIåŒ¹é…
        updated_count = 0
        for part in cleaned_parts:
            # åªæ›´æ–°æœªåŒ¹é…çš„é›¶ä»¶
            if not part.get('bom_code'):
                geometry_name = part['geometry_name']
                if geometry_name in ai_match_map:
                    ai_match = ai_match_map[geometry_name]
                    part['bom_code'] = ai_match['matched_bom_code']
                    part['match_method'] = f"AIåŒ¹é…(ç½®ä¿¡åº¦{ai_match['confidence']:.2f})"
                    part['confidence'] = ai_match['confidence']
                    part['ai_reason'] = ai_match.get('reason', '')
                    updated_count += 1
        
        print(f"   æ›´æ–°äº† {updated_count} ä¸ªé›¶ä»¶çš„åŒ¹é…ç»“æœ")
        
        return cleaned_parts

