#!/usr/bin/env python3

# -*- coding: utf-8 -*-

"""

åŒé€šé“è§£æå™¨ - ä¸¥æ ¼æŒ‰ç…§æ€»è®¾è®¡æ€è·¯å®ç°

PDF â†’ è§†è§‰é€šé“ + æ–‡æœ¬é€šé“ â†’ å€™é€‰äº‹å®JSON

"""



import os

import json

import tempfile

from pathlib import Path

from typing import Dict, List, Any, Optional



import fitz  # PyMuPDF

from pypdf import PdfReader

from models.vision_model import Qwen3VLModel





class DualChannelParser:

    """åŒé€šé“PDFè§£æå™¨"""



    def __init__(self, progress_reporter=None):

        self.vision_model = Qwen3VLModel()

        self.progress_reporter = progress_reporter



    def _report_progress(self, stage: str, progress: int, message: str, data: Dict = None):

        """æŠ¥å‘Šè¿›åº¦"""

        if self.progress_reporter:

            self.progress_reporter.report_progress(stage, progress, message, data)



    def _log(self, message: str, level: str = "info"):

        """è®°å½•æ—¥å¿—"""

        print(f"[{level.upper()}] {message}")

        if self.progress_reporter:

            self.progress_reporter.log(message, level)



    def parse_multi_pdfs(self, pdf_paths: List[str]) -> Dict[str, Any]:
        """
        è§£æå¤šä¸ªPDFæ–‡ä»¶ï¼Œåˆå¹¶BOMåè¿›è¡Œè§†è§‰åˆ†æ

        Args:
            pdf_paths: PDFæ–‡ä»¶è·¯å¾„åˆ—è¡¨

        Returns:
            å€™é€‰äº‹å®JSON
        """
        import os
        import re
        from pypdf import PdfReader

        print(f"ğŸ” å¼€å§‹å¤šPDFåŒé€šé“è§£æ: {len(pdf_paths)} ä¸ªæ–‡ä»¶")

        # æ­¥éª¤1ï¼šä»æ‰€æœ‰PDFæå–BOMï¼ˆæ–‡æœ¬é€šé“ï¼‰
        print("\n" + "="*80)
        print("æ­¥éª¤1: æ–‡æœ¬é€šé“è§£æ - ä»æ‰€æœ‰PDFæå–BOMè¡¨")
        print("="*80)

        all_bom_items = []

        for i, pdf_path in enumerate(pdf_paths, 1):
            print(f"\nğŸ“„ å¤„ç†ç¬¬ {i}/{len(pdf_paths)} ä¸ªPDF: {os.path.basename(pdf_path)}")

            # ä½¿ç”¨pypdfæå–BOM
            bom_items = self._extract_bom_from_pdf(pdf_path)

            if bom_items:
                # æ·»åŠ æ¥æºä¿¡æ¯
                for item in bom_items:
                    item["source_pdf"] = os.path.basename(pdf_path)

                all_bom_items.extend(bom_items)
                print(f"   âœ… æå–åˆ° {len(bom_items)} ä¸ªBOMé¡¹")
            else:
                print(f"   âš ï¸  æœªæå–åˆ°BOMé¡¹")

        print(f"\nâœ… æ–‡æœ¬é€šé“å®Œæˆï¼Œå…±æå– {len(all_bom_items)} ä¸ªBOMé¡¹")

        # æ­¥éª¤2ï¼šåˆå¹¶æ‰€æœ‰PDFé¡µé¢ï¼Œè¿›è¡Œè§†è§‰åˆ†æ
        print("\n" + "="*80)
        print("æ­¥éª¤2: è§†è§‰é€šé“è§£æ - è£…é…ä¸“å®¶åˆ†æï¼ˆä¼ å…¥æ‰€æœ‰BOMä¸Šä¸‹æ–‡ï¼‰")
        print("="*80)

        # åˆå¹¶æ‰€æœ‰PDFçš„é¡µé¢åˆ°ä¸´æ—¶ç›®å½•
        temp_dir = tempfile.mkdtemp()
        print(f"ğŸ“ åˆ›å»ºä¸´æ—¶ç›®å½•: {temp_dir}")

        all_image_paths = []
        total_pages = 0

        for pdf_path in pdf_paths:
            doc = fitz.open(pdf_path)
            total_pages += len(doc)

            for page_num in range(len(doc)):
                page = doc[page_num]

                # é«˜åˆ†è¾¨ç‡æ¸²æŸ“
                mat = fitz.Matrix(3, 3)  # 3å€ç¼©æ”¾
                pix = page.get_pixmap(matrix=mat)

                img_path = f"{temp_dir}/pdf{len(all_image_paths) + 1}_page{page_num + 1}.png"
                pix.save(img_path)
                all_image_paths.append(img_path)

            doc.close()

        print(f"ğŸ“„ æ€»é¡µæ•°: {total_pages}ï¼Œå·²è½¬æ¢ä¸º {len(all_image_paths)} å¼ å›¾ç‰‡")
        print(f"ğŸ“Š BOMä¸Šä¸‹æ–‡: {len(all_bom_items)} ä¸ªé›¶ä»¶")

        # è°ƒç”¨è§†è§‰æ¨¡å‹åˆ†ææ‰€æœ‰å›¾ç‰‡
        vision_results = self._vision_channel_parse_images(
            image_paths=all_image_paths,
            bom_items=all_bom_items
        )

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import shutil
        shutil.rmtree(temp_dir)
        print("ğŸ—‘ï¸  å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶")

        # åˆå¹¶ç»“æœ
        result = {
            "bom_candidates": all_bom_items,
            "vision_channel": vision_results,
            "pdf_count": len(pdf_paths),
            "total_pages": total_pages
        }

        print("\nâœ… åŒé€šé“è§£æå®Œæˆ")

        return result

    def _extract_bom_from_pdf(self, pdf_path: str) -> List[Dict]:
        """ä»å•ä¸ªPDFæå–BOMè¡¨"""
        try:
            from pypdf import PdfReader
            import re

            reader = PdfReader(pdf_path)
            all_text = ""
            for page in reader.pages:
                all_text += page.extract_text() + "\n"

            bom_items = []
            seen_codes = set()
            lines = all_text.split('\n')

            for line in lines:
                if not line.strip() or 'åºå·' in line or 'ç‰©æ–™ä»£ç ' in line:
                    continue

                parts = line.split()
                if len(parts) < 4:
                    continue

                # ç¬¬ä¸€ä¸ªåº”è¯¥æ˜¯åºå·
                try:
                    seq = int(parts[0])
                    if not (1 <= seq <= 200):
                        continue
                except:
                    continue

                # æŸ¥æ‰¾BOMä»£å·
                code = None
                code_idx = -1
                for i, part in enumerate(parts[1:], 1):
                    if re.match(r'^\d{2}\.\d{2}\.', part):
                        code = part
                        code_idx = i
                        break

                if not code or code in seen_codes:
                    continue
                seen_codes.add(code)

                # æå–äº§å“ä»£å·
                product_code = ""
                if code_idx + 1 < len(parts):
                    next_part = parts[code_idx + 1]
                    if any(c in next_part for c in ['-', '*', 'Ï†', 'Î¦', 'M', 'T-']):
                        product_code = next_part

                # æå–åç§°
                name_start_idx = code_idx + 2 if product_code else code_idx + 1
                name_parts = []
                for i in range(name_start_idx, len(parts) - 2):
                    name_parts.append(parts[i])
                name = ' '.join(name_parts) if name_parts else "æœªçŸ¥"

                # æå–æ•°é‡
                try:
                    qty = int(parts[-2])
                    weight = float(parts[-1])
                except:
                    try:
                        qty = int(parts[-3])
                        weight = float(parts[-1])
                    except:
                        continue

                bom_items.append({
                    "seq": str(seq),
                    "code": code,
                    "product_code": product_code,
                    "name": name,
                    "specification": "",
                    "quantity": qty,
                    "weight": weight,
                    "material": ""
                })

            return bom_items
        except Exception as e:
            print(f"   âŒ BOMæå–å¤±è´¥: {e}")
            return []

    def parse_pdf(self, pdf_path: str) -> Dict[str, Any]:

        """

        åŒé€šé“è§£æPDFï¼Œè¾“å‡ºå€™é€‰äº‹å®JSON



        æµç¨‹ï¼šå…ˆæ–‡æœ¬è§£æBOM â†’ å†æŠŠBOMä¼ ç»™è§†è§‰æ¨¡å‹ï¼ˆé¡ºåºæ‰§è¡Œï¼‰



        Args:

            pdf_path: PDFæ–‡ä»¶è·¯å¾„ï¼ˆå•ä¸ªPDFï¼‰æˆ–PDFæ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼ˆå¤šä¸ªPDFï¼‰



        Returns:

            å€™é€‰äº‹å®JSONï¼Œç¬¦åˆè®¾è®¡æ–‡æ¡£æ ¼å¼

        """

        # æ”¯æŒå•ä¸ªPDFæˆ–å¤šä¸ªPDF
        if isinstance(pdf_path, list):
            return self.parse_multi_pdfs(pdf_path)

        print(f"ğŸ” å¼€å§‹åŒé€šé“è§£æ: {pdf_path}")



        # 1. åŸºç¡€ä¿¡æ¯æå–

        doc = fitz.open(pdf_path)

        pages_info = []



        for page_num in range(len(doc)):

            page = doc[page_num]

            rect = page.rect

            pages_info.append({

                "page_id": page_num + 1,

                "width_px": int(rect.width * 4),  # å‡è®¾300DPI

                "height_px": int(rect.height * 4)

            })



        # 2. æ–‡æœ¬é€šé“è§£æï¼ˆå…ˆæ‰§è¡Œï¼‰

        print("\n" + "="*80)

        print("æ­¥éª¤1: æ–‡æœ¬é€šé“è§£æ - æå–BOMè¡¨")

        print("="*80)

        text_channel_results = self._text_channel_parse(pdf_path, doc)

        bom_items = text_channel_results.get("bom_items", [])

        print(f"âœ… æ–‡æœ¬é€šé“å®Œæˆï¼Œæå–åˆ° {len(bom_items)} ä¸ªBOMé¡¹ç›®")



        # 3. è§†è§‰é€šé“è§£æï¼ˆåæ‰§è¡Œï¼Œä¼ å…¥BOMæ•°æ®ï¼‰

        print("\n" + "="*80)

        print("æ­¥éª¤2: è§†è§‰é€šé“è§£æ - è£…é…ä¸“å®¶åˆ†æï¼ˆä¼ å…¥BOMä¸Šä¸‹æ–‡ï¼‰")

        print("="*80)

        vision_channel_results = self._vision_channel_parse(pdf_path, doc, bom_items)

        print(f"âœ… è§†è§‰é€šé“å®Œæˆ")



        # 4. åˆå¹¶ä¸ºå€™é€‰äº‹å®JSON

        print("\n" + "="*80)

        print("æ­¥éª¤3: åˆå¹¶åŒé€šé“ç»“æœ")

        print("="*80)

        candidate_facts = self._merge_channels(

            pages_info,

            text_channel_results,

            vision_channel_results

        )



        doc.close()



        print(f"\nâœ… åŒé€šé“è§£æå®Œæˆï¼Œå€™é€‰äº‹å®æ•°é‡: {len(candidate_facts.get('bom_candidates', []))}")

        return candidate_facts

    

    def _text_channel_parse(self, pdf_path: str, doc) -> Dict[str, Any]:

        """æ–‡æœ¬é€šé“ï¼šä½¿ç”¨pypdfæå–æ–‡æœ¬ + BOMè§£æï¼ˆå®Œå…¨å‚è€ƒå‚è€ƒé¡¹ç›®ï¼‰"""

        print("ğŸ“„ æ–‡æœ¬é€šé“è§£æä¸­...")

        print(f"[DEBUG] æ–‡æœ¬é€šé“ - PDFè·¯å¾„: {pdf_path}")



        # æŠ¥å‘Šè¿›åº¦ï¼šæ–‡æœ¬æå–å¼€å§‹

        self._report_progress("pdf_bom", 10, "æ­£åœ¨æå–BOMè¡¨...", {

            "current_task": "text_extraction",

            "text_extraction": {

                "message": "pypdfæ–‡æœ¬æå–ä¸­...",

                "bom_candidates": 0

            }

        })

        self._log("ğŸ“„ å¼€å§‹PDFæ–‡æœ¬æå–", "info")



        results = {

            "text_content": [],

            "bom_items": [],

            "tech_requirements": []

        }



        # ä½¿ç”¨pypdfæå–æ–‡æœ¬ï¼ˆå‚è€ƒå‚è€ƒé¡¹ç›®çš„æ–¹æ³•ï¼‰

        try:

            reader = PdfReader(pdf_path)

        except Exception as e:

            print(f"âŒ pypdfè¯»å–å¤±è´¥: {e}")

            return results



        # æå–æ‰€æœ‰é¡µé¢æ–‡æœ¬

        text_chunks = []

        for page in reader.pages:

            page_text = page.extract_text() or ""

            if page_text:

                text_chunks.append(page_text)



        combined_text = "\n".join(text_chunks)



        # ä½¿ç”¨å‚è€ƒé¡¹ç›®çš„æ–¹æ³•æå–BOMé¡¹ç›®

        bom_items = self._extract_bom_from_text(combined_text)

        results["bom_items"] = bom_items

        print(f"ğŸ“¦ æå–åˆ° {len(bom_items)} ä¸ªBOMé¡¹ç›®")



        # æå–æŠ€æœ¯è¦æ±‚

        for page_num, text in enumerate(text_chunks):

            tech_lines = self._extract_tech_requirements(text, page_num + 1)

            results["tech_requirements"].extend(tech_lines)



        print(f"âœ… æ–‡æœ¬é€šé“å®Œæˆ - BOM: {len(results['bom_items'])}, æŠ€æœ¯è¦æ±‚: {len(results['tech_requirements'])}")



        # æŠ¥å‘Šè¿›åº¦ï¼šæ–‡æœ¬æå–å®Œæˆ

        self._report_progress("pdf_bom", 30, "æ–‡æœ¬æå–å®Œæˆ", {

            "current_task": "vision_analysis",

            "text_extraction": {

                "message": "æ–‡æœ¬æå–å®Œæˆ",

                "bom_candidates": len(bom_items)

            },

            "text_extraction_done": True

        })

        self._log(f"âœ… PDFæ–‡æœ¬æå–å®Œæˆ: {len(bom_items)}ä¸ªBOMé¡¹", "success")



        return results

    

    def _vision_channel_parse_images(self, image_paths: List[str], bom_items: List[Dict]) -> Dict[str, Any]:
        """
        è§†è§‰é€šé“ï¼šä½¿ç”¨å·²æœ‰çš„å›¾ç‰‡è·¯å¾„è¿›è¡Œè£…é…åˆ†æ

        Args:
            image_paths: å›¾ç‰‡è·¯å¾„åˆ—è¡¨
            bom_items: BOMæ•°æ®

        Returns:
            è§†è§‰åˆ†æç»“æœ
        """
        print("ğŸ‘ï¸ è§†è§‰é€šé“è§£æä¸­ï¼ˆè£…é…ä¸“å®¶CoTæ¨ç†æ¨¡å¼ï¼‰...")
        print(f"ğŸ“Š BOMä¸Šä¸‹æ–‡: {len(bom_items)} ä¸ªé›¶ä»¶")
        print(f"ğŸ“„ å›¾ç‰‡æ•°é‡: {len(image_paths)} å¼ ")

        # è°ƒç”¨è£…é…ä¸“å®¶æ¨¡å‹
        from prompts.agent_1_vision_prompts import build_assembly_expert_prompt

        system_prompt, user_prompt = build_assembly_expert_prompt(
            bom_context=bom_items,
            enable_cot=True
        )

        print(f"\nğŸ¤– è°ƒç”¨è£…é…ä¸“å®¶æ¨¡å‹ï¼ˆCoTæ¨ç†æ¨¡å¼ï¼‰")
        print(f"   ğŸ“„ å›¾çº¸: {len(image_paths)} é¡µ")
        print(f"   ğŸ“¦ BOM: {len(bom_items)} ä¸ªé›¶ä»¶")

        # è°ƒç”¨Qwen-VL
        self._log(f"ğŸ¤– Qwen-VLè§†è§‰æ™ºèƒ½ä½“å¯åŠ¨ï¼Œåˆ†æ{len(image_paths)}é¡µå›¾çº¸...", "info")

        import json

        # å‡†å¤‡æ¶ˆæ¯ï¼ˆå¤šå›¾æ ¼å¼ï¼‰
        content = []

        # æ·»åŠ æ‰€æœ‰å›¾ç‰‡
        for img_path in image_paths:
            if img_path.startswith('http'):
                image_url = img_path
            else:
                image_url = self.vision_model.encode_image_to_base64(img_path)

            content.append({
                "type": "image_url",
                "image_url": {"url": image_url}
            })

        # æ·»åŠ ç”¨æˆ·æç¤ºè¯
        content.append({
            "type": "text",
            "text": user_prompt
        })

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": content}
        ]

        # è°ƒç”¨API
        print(f"   ğŸ”„ æ­£åœ¨è°ƒç”¨ qwen-vl-plus...")

        response = self.vision_model.client.chat.completions.create(
            model="qwen-vl-plus",
            messages=messages,
            temperature=0.1,
            max_tokens=8000,
            stream=True
        )

        # æ”¶é›†å“åº”
        answer_content = ""
        for chunk in response:
            if chunk.choices[0].delta.content:
                answer_content += chunk.choices[0].delta.content
                print(".", end="", flush=True)

        print()  # æ¢è¡Œ

        # è§£æJSON
        try:
            if "```json" in answer_content:
                json_start = answer_content.find("```json") + 7
                json_end = answer_content.find("```", json_start)
                json_str = answer_content[json_start:json_end].strip()
            else:
                json_start = answer_content.find('{')
                json_end = answer_content.rfind('}') + 1
                json_str = answer_content[json_start:json_end]

            result = json.loads(json_str)
            print(f"   âœ… JSONè§£ææˆåŠŸ")

            return result

        except Exception as e:
            print(f"   âš ï¸  JSONè§£æå¤±è´¥: {e}")
            return {}

    def _vision_channel_parse(self, pdf_path: str, doc, bom_items: List[Dict]) -> Dict[str, Any]:

        """

        è§†è§‰é€šé“ï¼šå¤šå›¾ä¸€æ¬¡æ€§é€å…¥Qwen-VLè¿›è¡Œè£…é…åˆ†æ



        Args:

            pdf_path: PDFæ–‡ä»¶è·¯å¾„

            doc: PyMuPDFæ–‡æ¡£å¯¹è±¡

            bom_items: æ–‡æœ¬é€šé“æå–çš„BOMæ•°æ®

        """

        print("ğŸ‘ï¸ è§†è§‰é€šé“è§£æä¸­ï¼ˆè£…é…ä¸“å®¶CoTæ¨ç†æ¨¡å¼ï¼‰...")

        print(f"ğŸ“Š BOMä¸Šä¸‹æ–‡: {len(bom_items)} ä¸ªé›¶ä»¶")



        results = {

            "assembly_analysis": {}  # å®Œæ•´çš„è£…é…åˆ†æç»“æœ

        }



        # è½¬æ¢æ‰€æœ‰PDFé¡µé¢ä¸ºå›¾ç‰‡

        temp_dir = tempfile.mkdtemp()

        print(f"ğŸ“ åˆ›å»ºä¸´æ—¶ç›®å½•: {temp_dir}")

        print(f"ğŸ“„ PDFæ€»é¡µæ•°: {len(doc)}")



        image_paths = []

        for page_num in range(len(doc)):

            page = doc[page_num]

            print(f"ğŸ–¼ï¸  è½¬æ¢ç¬¬ {page_num + 1} é¡µä¸ºå›¾ç‰‡...")



            # é«˜åˆ†è¾¨ç‡æ¸²æŸ“

            mat = fitz.Matrix(3, 3)  # 3å€ç¼©æ”¾ï¼Œçº¦225DPI

            pix = page.get_pixmap(matrix=mat)

            img_path = f"{temp_dir}/page_{page_num + 1}.png"

            pix.save(img_path)

            image_paths.append(img_path)

            print(f"   âœ… å·²ä¿å­˜: {img_path}, å°ºå¯¸: {pix.width}x{pix.height}")



        # æŠ¥å‘Šè¿›åº¦ï¼šè§†è§‰åˆ†æå¼€å§‹

        self._report_progress("pdf_bom", 50, "ğŸ¤– Qwen-VLè§†è§‰æ™ºèƒ½ä½“åˆ†æä¸­...", {

            "current_task": "vision_analysis",

            "vision_analysis": {

                "message": "ğŸ¤– Qwen-VLåˆ†æå›¾çº¸ç»“æ„...",

                "assembly_relations": 0,

                "requirements": 0

            }

        })

        self._log(f"ğŸ¤– Qwen-VLè§†è§‰æ™ºèƒ½ä½“å¯åŠ¨ï¼Œåˆ†æ{len(image_paths)}é¡µå›¾çº¸...", "info")



        # ä¸€æ¬¡æ€§è°ƒç”¨è§†è§‰æ¨¡å‹åˆ†ææ‰€æœ‰å›¾ç‰‡ï¼ˆä¼ å…¥BOMä¸Šä¸‹æ–‡ï¼‰

        try:

            print(f"\nğŸ¤– è°ƒç”¨è£…é…ä¸“å®¶æ¨¡å‹ï¼ˆCoTæ¨ç†æ¨¡å¼ï¼‰")

            print(f"   ğŸ“„ å›¾çº¸: {len(image_paths)} é¡µ")

            print(f"   ğŸ“¦ BOM: {len(bom_items)} ä¸ªé›¶ä»¶")



            vision_result = self._call_assembly_expert_model(image_paths, bom_items)



            if vision_result and vision_result.get("success"):

                data = vision_result.get("result", {})



                # âœ… æ–°çš„æ•°æ®ç»“æ„ï¼šç›´æ¥è¿”å›å®Œæ•´çš„è£…é…åˆ†æç»“æœ

                results["assembly_analysis"] = data



                print(f"\nâœ… è£…é…ä¸“å®¶åˆ†æå®Œæˆ")

                print(f"   ğŸ“‹ äº§å“æ€»è§ˆ: {data.get('product_overview', {}).get('product_name', 'æœªçŸ¥')}")

                print(f"   ğŸ”— å›¾å·æ˜ å°„: {len(data.get('drawing_number_to_bom', []))} é¡¹")

                print(f"   ğŸ“ ç©ºé—´å…³ç³»: {len(data.get('spatial_relationships', []))} é¡¹")

                print(f"   ğŸ”§ è£…é…è¿æ¥: {len(data.get('assembly_connections', []))} é¡¹")

                print(f"   ğŸ“ å…³é”®å°ºå¯¸: {len(data.get('critical_dimensions', []))} é¡¹")

                print(f"   ğŸ’¡ è£…é…çº¿ç´¢: {len(data.get('assembly_sequence_hints', []))} æ¡")

                print(f"   ğŸ”¥ ç„Šæ¥ä¿¡æ¯: {len(data.get('welding_info', []))} é¡¹")



                # æŠ¥å‘Šè¿›åº¦ï¼šè§†è§‰åˆ†æå®Œæˆ

                self._report_progress("pdf_bom", 70, "è§†è§‰åˆ†æå®Œæˆ", {

                    "current_task": "bom_generation",

                    "vision_analysis": {

                        "message": "è§†è§‰åˆ†æå®Œæˆ",

                        "assembly_connections": len(data.get('assembly_connections', [])),

                        "critical_dimensions": len(data.get('critical_dimensions', []))

                    },

                    "vision_analysis_done": True

                })

                self._log(f"âœ… Qwen-VLè§†è§‰åˆ†æå®Œæˆ: {len(data.get('assembly_connections', []))}ä¸ªè£…é…è¿æ¥, {len(data.get('critical_dimensions', []))}ä¸ªå…³é”®å°ºå¯¸", "success")

            else:

                error_msg = vision_result.get("error", "æœªçŸ¥é”™è¯¯") if vision_result else "æœªè¿”å›ç»“æœ"

                print(f"âŒ è£…é…ä¸“å®¶åˆ†æå¤±è´¥: {error_msg}")

                self._log(f"âš ï¸ Qwen-VLè§†è§‰åˆ†æå¤±è´¥: {error_msg}", "error")

                raise RuntimeError(error_msg)



        except Exception as e:

            error_msg = f"è§†è§‰é€šé“è§£æå¤±è´¥: {e}"

            print(f"âš ï¸ {error_msg}")

            import traceback

            traceback.print_exc()

            self._log(f"âš ï¸ {error_msg}", "error")

            raise

        finally:

            import shutil

            shutil.rmtree(temp_dir, ignore_errors=True)

            print(f"ğŸ—‘ï¸  å·²æ¸…ç†ä¸´æ—¶æ–‡ä»¶")



        return results

    

    def _call_assembly_expert_model(self, image_paths: List[str], bom_items: List[Dict]) -> Dict[str, Any]:

        """

        è°ƒç”¨è£…é…ä¸“å®¶æ¨¡å‹ï¼ˆå¤šå›¾è¾“å…¥ + BOMä¸Šä¸‹æ–‡ï¼‰- å¸¦é‡è¯•æœºåˆ¶



        Args:

            image_paths: æ‰€æœ‰å›¾ç‰‡è·¯å¾„åˆ—è¡¨

            bom_items: BOMè¡¨æ•°æ®



        Returns:

            è£…é…ä¸“å®¶åˆ†æç»“æœ

        """

        from prompts.agent_1_vision_prompts import build_vision_prompt



        # âœ… æ·»åŠ é‡è¯•æœºåˆ¶

        max_retries = 3

        last_error = None



        for attempt in range(max_retries):

            try:

                self._log(f"ğŸ¤– Qwen-VLè§†è§‰æ™ºèƒ½ä½“å¯åŠ¨ï¼ˆå°è¯• {attempt+1}/{max_retries}ï¼‰ï¼Œåˆ†æ{len(image_paths)}é¡µå›¾çº¸...", "info")



                # æ„å»ºç³»ç»Ÿæç¤ºè¯ï¼ˆè£…é…ä¸“å®¶CoTæ¨¡å¼ï¼‰

                system_prompt = build_vision_prompt(focus_areas=['assembly'])



                # ç®€åŒ–BOMæ•°æ®ï¼Œåªä¿ç•™å…³é”®å­—æ®µ

                simplified_bom = []

                for item in bom_items:

                    simplified_bom.append({

                        "seq": item.get("seq", ""),

                        "code": item.get("code", ""),

                        "name": item.get("name", ""),

                        "qty": item.get("qty", 0),

                        "weight": item.get("weight", 0)

                    })



                # æ„å»ºç”¨æˆ·æŸ¥è¯¢ï¼ˆä½¿ç”¨æ–°çš„è§†è§‰åˆ†ææ¨¡æ¿ï¼‰
                from prompts.agent_1_vision_prompts import ASSEMBLY_USER_QUERY_TEMPLATE

                # åªæå–ä¸»è¦ç»“æ„ä»¶ï¼ˆBOMä»£å·ä»¥"01."å¼€å¤´ï¼‰
                main_parts = [item for item in simplified_bom if item.get("code", "").startswith("01.")]

                user_query = f"""æˆ‘æä¾›äº†è¿™ä¸ªäº§å“çš„æ‰€æœ‰å·¥ç¨‹å›¾çº¸ï¼ˆ{len(image_paths)}é¡µï¼‰å’ŒBOMè¡¨æ•°æ®ã€‚

**BOMè¡¨ä¸­çš„ä¸»è¦ç»“æ„ä»¶ï¼ˆå…±{len(main_parts)}ä¸ªï¼‰ï¼š**

```json
{json.dumps(main_parts[:15], ensure_ascii=False, indent=2)}
```

{ASSEMBLY_USER_QUERY_TEMPLATE}

"""



                # æ„å»ºå¤šå›¾æ¶ˆæ¯å†…å®¹

                content = []



                # æ·»åŠ æ‰€æœ‰å›¾ç‰‡

                for img_path in image_paths:

                    # ç¼–ç å›¾ç‰‡ä¸ºbase64

                    image_url = self.vision_model.encode_image_to_base64(img_path)

                    content.append({

                        "type": "image_url",

                        "image_url": {"url": image_url}

                    })



                # æ·»åŠ æ–‡æœ¬æŸ¥è¯¢ï¼ˆåŒ…å«BOMï¼‰

                content.append({

                    "type": "text",

                    "text": user_query

                })



                # æ„å»ºæ¶ˆæ¯

                messages = [

                    {

                        "role": "system",

                        "content": system_prompt

                    },

                    {

                        "role": "user",

                        "content": content

                    }

                ]



                # è°ƒç”¨APIï¼ˆä½¿ç”¨qwen-vl-plusï¼‰

                print(f"ğŸ”„ æ­£åœ¨è°ƒç”¨ {self.vision_model.model_name}...")

                completion = self.vision_model.client.chat.completions.create(

                    model=self.vision_model.model_name,

                    messages=messages,

                    stream=True,

                    # âš ï¸ ä¸é™åˆ¶max_tokensï¼Œè®©æ¨¡å‹å®Œæ•´è¾“å‡ºæ‰€æœ‰é›¶ä»¶çš„è£…é…æŒ‡å¯¼
                    # max_tokens=4000,  # ä¹‹å‰é™åˆ¶å¯¼è‡´JSONè¢«æˆªæ–­

                    extra_body={

                        'enable_thinking': False,  # è£…é…åˆ†æä¸éœ€è¦æ€è€ƒè¿‡ç¨‹

                    }

                )



                # å¤„ç†æµå¼å“åº”

                answer_content = ""



                for chunk in completion:

                    if not chunk.choices:

                        continue



                    delta = chunk.choices[0].delta

                    if delta.content:

                        answer_content += delta.content

                        print(".", end="", flush=True)  # æ˜¾ç¤ºè¿›åº¦



                print()  # æ¢è¡Œ



                # è§£æJSONç»“æœï¼ˆå¢å¼ºå®¹é”™ï¼‰

                # ç§»é™¤markdownä»£ç å—æ ‡è®°

                content = answer_content.strip()

                if content.startswith('```json'):

                    content = content[7:]  # ç§»é™¤ ```json

                if content.startswith('```'):

                    content = content[3:]  # ç§»é™¤ ```

                if content.endswith('```'):

                    content = content[:-3]  # ç§»é™¤ç»“å°¾çš„ ```



                content = content.strip()



                # æŸ¥æ‰¾JSONçš„å¼€å§‹å’Œç»“æŸ

                json_start = content.find('{')

                json_end = content.rfind('}') + 1



                if json_start >= 0 and json_end > json_start:

                    json_str = content[json_start:json_end]



                    # å°è¯•è§£æJSON

                    try:

                        parsed_result = json.loads(json_str)

                        print(f"âœ… JSONè§£ææˆåŠŸ")

                        self._log(f"âœ… Qwen-VLè§†è§‰åˆ†æå®Œæˆï¼ˆç¬¬{attempt+1}æ¬¡å°è¯•æˆåŠŸï¼‰", "success")

                    except json.JSONDecodeError as e:

                        # âœ… ä¿®å¤: JSONè§£æå¤±è´¥æ—¶ï¼ŒæŠ›å‡ºå¼‚å¸¸è§¦å‘é‡è¯•

                        error_msg = f"JSONè§£æå¤±è´¥: line {e.lineno} column {e.colno} (char {e.pos})"

                        print(f"[DEBUG] {error_msg}")

                        self._log(f"âš ï¸ {error_msg}ï¼ˆå°è¯• {attempt+1}/{max_retries}ï¼‰", "warning")

                        raise json.JSONDecodeError(error_msg, json_str, e.pos)

                else:

                    # âœ… ä¿®å¤: æœªæ‰¾åˆ°JSONæ—¶ï¼ŒæŠ›å‡ºå¼‚å¸¸è§¦å‘é‡è¯•

                    error_msg = "æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONæ•°æ®"

                    self._log(f"âš ï¸ {error_msg}ï¼ˆå°è¯• {attempt+1}/{max_retries}ï¼‰", "warning")

                    raise ValueError(error_msg)



                # ä¿å­˜è¾“å‡ºç»“æœåˆ°ä¸´æ—¶æ–‡ä»¶

                import datetime

                timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

                output_dir = "debug_output"

                os.makedirs(output_dir, exist_ok=True)



                output_file = os.path.join(output_dir, f"assembly_expert_output_{timestamp}.json")

                result_data = {

                    "success": True,

                    "model": self.vision_model.model_name,

                    "timestamp": timestamp,

                    "image_count": len(image_paths),

                    "attempt": attempt + 1,

                    "result": parsed_result,

                    "raw_response": answer_content

                }



                with open(output_file, 'w', encoding='utf-8') as f:

                    json.dump(result_data, f, ensure_ascii=False, indent=2)



                print(f"ğŸ’¾ è£…é…ä¸“å®¶è¾“å‡ºå·²ä¿å­˜: {output_file}")



                # âœ… æˆåŠŸè§£æï¼Œè¿”å›ç»“æœ

                return {

                    "success": True,

                    "result": parsed_result,

                    "raw_response": answer_content

                }



            except (json.JSONDecodeError, ValueError) as e:

                # âœ… JSONè§£æå¤±è´¥ï¼Œè®°å½•é”™è¯¯å¹¶é‡è¯•

                last_error = e

                if attempt < max_retries - 1:

                    # è¿˜æœ‰é‡è¯•æœºä¼šï¼Œç­‰å¾…åé‡è¯•

                    import time

                    time.sleep(2)

                    continue

                else:

                    # æœ€åä¸€æ¬¡å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸

                    error_msg = f"Qwen-VLè°ƒç”¨å¤±è´¥ï¼ˆå·²é‡è¯•{max_retries}æ¬¡ï¼‰: {str(e)}"

                    self._log(f"âŒ {error_msg}", "error")

                    raise Exception(error_msg)



            except Exception as e:

                # âœ… å…¶ä»–å¼‚å¸¸ï¼Œè®°å½•é”™è¯¯å¹¶é‡è¯•

                last_error = e

                print(f"âŒ è°ƒç”¨è£…é…ä¸“å®¶æ¨¡å‹å¼‚å¸¸: {e}")

                import traceback

                traceback.print_exc()



                if attempt < max_retries - 1:

                    # è¿˜æœ‰é‡è¯•æœºä¼šï¼Œç­‰å¾…åé‡è¯•

                    import time

                    time.sleep(2)

                    continue

                else:

                    # æœ€åä¸€æ¬¡å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸

                    error_msg = f"Qwen-VLè°ƒç”¨å¤±è´¥ï¼ˆå·²é‡è¯•{max_retries}æ¬¡ï¼‰: {str(e)}"

                    self._log(f"âŒ {error_msg}", "error")

                    raise Exception(error_msg)



        # âœ… ç†è®ºä¸Šä¸ä¼šåˆ°è¿™é‡Œï¼Œä½†ä¸ºäº†å®‰å…¨èµ·è§

        raise Exception(f"Qwen-VLè°ƒç”¨å¤±è´¥: {str(last_error)}")



    def _call_vision_model_with_design_prompt(self, img_path: str, page_id: int, width: int, height: int) -> Dict[str, Any]:

        """ä½¿ç”¨è®¾è®¡æ–‡æ¡£ä¸­çš„ç³»ç»Ÿæç¤ºè¯è°ƒç”¨è§†è§‰æ¨¡å‹"""

        

        # è®¾è®¡æ–‡æ¡£ä¸­çš„ç³»ç»Ÿæç¤ºè¯

        system_prompt = """ä½ æ˜¯"å·¥ç¨‹å›¾è§†è§‰è§£ææ™ºèƒ½ä½“"ã€‚ä½ çš„èŒè´£æ˜¯ï¼šä»è¾“å…¥çš„å·¥ç¨‹å›¾é¡µé¢å›¾åƒä¸­ï¼Œç²¾å‡†æŠ½å–ç”¨äºè£…é…/å·¥è‰ºè§„åˆ’çš„å€™é€‰äº‹å®ï¼Œå¹¶è¾“å‡ºç»“æ„åŒ– JSONã€‚



ä½ åªåšè§†è§‰ä¸ç‰ˆé¢ç†è§£ï¼šåŒºåŸŸå®šä½ã€æ–‡å­—/OCRã€å°ºå¯¸å’Œç¬¦å·è¯†åˆ«ã€BOM è¡¨è§£æã€ç¼–å·æ°”æ³¡ä¸é›¶ä»¶å¯¹åº”ã€è§†å›¾ç±»å‹åˆ¤å®šã€‚ä¸è¦åšè£…é…é¡ºåºæˆ–å·¥è‰ºæ¨ç†ã€‚



å¿…é¡»éµå®ˆï¼š

1. å¯è¿½æº¯ï¼šæ¯ä¸ªç»“è®ºæä¾› evidenceï¼ˆpage_idã€region[x,y,w,h] æˆ– table_rowï¼‰ã€‚

2. ä¸è‡†é€ ï¼šçœ‹ä¸æ¸…æˆ–ä¸ç¡®å®šçš„å€¼ç”¨ "unknown"ï¼Œå¹¶åœ¨ confidence é™ä½ã€‚

3. è§„èŒƒè¾“å‡ºï¼šä¸¥æ ¼æŒ‰"å€™é€‰äº‹å® JSON å¥‘çº¦"è¾“å‡ºï¼Œä¸è¦è¾“å‡ºå¤šä½™æ–‡æœ¬ã€‚

4. é²æ£’ OCRï¼šä¿®æ­£å¸¸è§ OCR é”™è¯¯ï¼Œä¿ç•™åŸæ–‡äº raw å­—æ®µã€‚

5. ç¬¦å·ä¼˜å…ˆï¼šä¼˜å…ˆè¯†åˆ«ç„Šæ¥ç¬¦å·ã€å½¢ä½å…¬å·®ã€ç²—ç³™åº¦ã€å€’è§’ã€æ¿åšã€å­”å¾„/å­”è·ç­‰å·¥ç¨‹è¦ç´ ã€‚



è¾“å‡ºï¼šä»…è¾“å‡ºå€™é€‰äº‹å® JSONï¼Œç¦æ­¢å…¶å®ƒå†…å®¹ã€‚"""

        

        user_query = f"""è¯·åˆ†æè¿™å¼ å·¥ç¨‹å›¾çº¸ï¼ˆé¡µé¢{page_id}ï¼Œå°ºå¯¸{width}x{height}ï¼‰ï¼ŒæŒ‰ç…§å€™é€‰äº‹å®JSONæ ¼å¼è¾“å‡ºç»“æœã€‚



é‡ç‚¹è¯†åˆ«ï¼š

1. é¡µé¢åŒºåŸŸï¼ˆæ ‡é¢˜æ ã€æŠ€æœ¯è¦æ±‚ã€BOMè¡¨ã€ä¸»è§†å›¾ã€ç­‰è½´æµ‹ã€å±€éƒ¨è§†å›¾ï¼‰

2. BOMè¡¨æ ¼å†…å®¹

3. å‡ ä½•å°ºå¯¸å’Œç¬¦å·

4. ç¼–å·æ°”æ³¡ä¸é›¶ä»¶å¯¹åº”

5. æŠ€æœ¯è¦æ±‚æ–‡æœ¬



è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ–‡å­—ã€‚"""

        

        try:

            print(f"[DEBUG] å¼€å§‹è°ƒç”¨vision_model.analyze_engineering_drawing...")

            result = self.vision_model.analyze_engineering_drawing(

                image_path=img_path,

                focus_areas=['assembly', 'welding'],

                drawing_type='è£…é…å›¾',

                custom_system_prompt=system_prompt,

                custom_user_query=user_query

            )

            print(f"[DEBUG] vision_modelè¿”å›: success={result.get('success')}")



            if result['success']:

                print(f"[DEBUG] è§£æè§†è§‰æ¨¡å‹ç»“æœ...")

                # å°è¯•è§£æJSONç»“æœ

                if isinstance(result['result'], str):

                    parsed = json.loads(result['result'])

                    print(f"[DEBUG] JSONè§£ææˆåŠŸï¼Œkeys: {parsed.keys() if isinstance(parsed, dict) else 'not dict'}")

                    return parsed

                else:

                    print(f"[DEBUG] ç»“æœå·²æ˜¯dictç±»å‹")

                    return result['result']

            else:

                print(f"âŒ è§†è§‰æ¨¡å‹è°ƒç”¨å¤±è´¥: {result.get('error')}")

                return {}



        except Exception as e:

            print(f"âŒ è§†è§‰æ¨¡å‹è§£æå¼‚å¸¸: {e}")

            import traceback

            traceback.print_exc()

            return {}

    

    def _extract_bom_from_text(self, raw_text: str) -> List[Dict[str, Any]]:

        """

        ä»æ–‡æœ¬ä¸­æå–BOMé¡¹ç›®ï¼ˆå‚è€ƒå‚è€ƒé¡¹ç›®çš„æ–¹æ³•ï¼‰



        BOMè¡Œæ ¼å¼é€šå¸¸ä¸ºï¼š

        åºå· ä»£å· åç§° [ææ–™/è§„æ ¼] æ•°é‡ [é‡é‡]

        ä¾‹å¦‚: 53 01.09.2556 T-SPV1830-EURO-09-Q235 æ–¹å½¢æ¿-æœºåŠ -é•€é”Œ 1 3.65

        """

        items = []



        for raw_line in raw_text.splitlines():

            line = raw_line.strip()

            if not line:

                continue



            tokens = line.split()



            # è‡³å°‘éœ€è¦4ä¸ªtoken: åºå· ä»£å· åç§° æ•°é‡

            if len(tokens) < 4:

                continue



            # ç¬¬ä¸€ä¸ªtokenå¿…é¡»æ˜¯æ•°å­—ï¼ˆåºå·ï¼‰

            if not tokens[0].isdigit():

                continue



            # ç¬¬äºŒä¸ªtokenåº”è¯¥æ˜¯ä»£å·ï¼ˆåŒ…å«å­—æ¯æˆ–ç‰¹æ®Šå­—ç¬¦ï¼‰

            code = tokens[1]

            if not self._looks_like_part_code(code):

                continue



            # è§£æåºå·

            try:

                index = int(tokens[0])

            except ValueError:

                continue



            # æŸ¥æ‰¾æœ€åçš„æ•°é‡ï¼ˆæ•´æ•°ï¼‰

            qty_info = self._find_last_int(tokens)

            # æŸ¥æ‰¾æœ€åçš„é‡é‡ï¼ˆæµ®ç‚¹æ•°ï¼‰

            weight_info = self._find_last_float(tokens)



            # ç¡®å®šåç§°çš„ç»“æŸä½ç½®

            desc_end = len(tokens)

            if qty_info:

                desc_end = min(desc_end, qty_info[1])

            elif weight_info:

                desc_end = min(desc_end, weight_info[1])



            # æå–åç§°ï¼ˆä»ç¬¬3ä¸ªtokenåˆ°desc_endï¼‰

            name_tokens = tokens[2:desc_end]

            if not name_tokens:

                name_tokens = tokens[1:desc_end]



            item = {

                "seq": str(index),

                "code": code,

                "name": " ".join(name_tokens),

                "qty": qty_info[0] if qty_info else "unknown",

                "weight": weight_info[0] if weight_info else None,

                "raw": line,

                "source": "text_extraction",

                "confidence": 0.85

            }

            items.append(item)



        return items



    def _looks_like_part_code(self, token: str) -> bool:

        """åˆ¤æ–­tokenæ˜¯å¦åƒé›¶ä»¶ä»£å·"""

        # åŒ…å«å­—æ¯

        if any(ch.isalpha() for ch in token):

            return True

        # åŒ…å«ç‰¹æ®Šå­—ç¬¦

        return any(ch in "-_.*/" for ch in token)



    def _find_last_int(self, tokens: List[str]) -> Optional[tuple]:

        """ä»åå¾€å‰æŸ¥æ‰¾æœ€åä¸€ä¸ªæ•´æ•°"""

        for idx in range(len(tokens) - 1, -1, -1):

            token = tokens[idx]

            if token.isdigit():

                try:

                    return int(token), idx

                except ValueError:

                    continue

        return None



    def _find_last_float(self, tokens: List[str]) -> Optional[tuple]:

        """ä»åå¾€å‰æŸ¥æ‰¾æœ€åä¸€ä¸ªæµ®ç‚¹æ•°"""

        for idx in range(len(tokens) - 1, -1, -1):

            token = tokens[idx]

            try:

                if any(ch.isdigit() for ch in token):

                    return float(token), idx

            except ValueError:

                continue

        return None



    def _extract_tech_requirements(self, text: str, page_id: int) -> List[Dict[str, Any]]:

        """ä»æ–‡æœ¬ä¸­æå–æŠ€æœ¯è¦æ±‚"""

        tech_requirements = []

        

        # ç®€å•è§„åˆ™åŒ¹é…æŠ€æœ¯è¦æ±‚

        lines = text.split('\n')

        for i, line in enumerate(lines):

            line = line.strip()

            

            # åŒ¹é…æŠ€æœ¯è¦æ±‚å…³é”®è¯

            if any(keyword in line for keyword in [

                'æŠ€æœ¯è¦æ±‚', 'æœªæ³¨', 'å…¬å·®', 'ç„Šæ¥', 'å–·æ¶‚', 'çƒ­å¤„ç†', 

                'è¡¨é¢', 'ç²¾åº¦', 'ææ–™', 'æ ‡å‡†'

            ]):

                if len(line) > 10:  # è¿‡æ»¤å¤ªçŸ­çš„è¡Œ

                    tech_requirements.append({

                        "text": line,

                        "source": "text_channel",

                        "evidence": {

                            "page_id": page_id,

                            "line_number": i + 1

                        },

                        "confidence": 0.8

                    })

        

        return tech_requirements

    



    def _merge_channels(self, pages_info: List[Dict], text_results: Dict, vision_results: Dict) -> Dict[str, Any]:

        """åˆå¹¶åŒé€šé“ç»“æœä¸ºå€™é€‰äº‹å®JSON"""



        candidate_facts = {

            "pages": pages_info,

            "regions": vision_results.get("regions", []),

            "bom_candidates": [],

            "feature_candidates": vision_results.get("feature_candidates", []),

            "note_candidates": [],

            "part_bubble_candidates": vision_results.get("part_bubble_candidates", []),

            "units_notes": [{"scope": "page", "unit": "mm", "confidence": 0.95}],

            "warnings": [],

            "vision_channel": vision_results.get("assembly_analysis", {})  # æ·»åŠ è§†è§‰é€šé“çš„è£…é…åˆ†æç»“æœ

        }



        # åˆå¹¶BOMå€™é€‰ï¼ˆä»æ–‡æœ¬æå–ï¼‰

        for item in text_results.get("bom_items", []):

            candidate_facts["bom_candidates"].append(item)



        # åˆå¹¶æŠ€æœ¯è¦æ±‚

        for tech_req in text_results.get("tech_requirements", []):

            candidate_facts["note_candidates"].append(tech_req)



        return candidate_facts

