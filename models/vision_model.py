# -*- coding: utf-8 -*-
"""
Qwen3-VLè§†è§‰æ¨¡å‹è°ƒç”¨æ¨¡å—
åŸºäºé˜¿é‡Œäº‘DashScope API
"""

import os
import json
import base64
import ssl
import certifi
from typing import Dict, List, Optional, Union
from openai import OpenAI
from prompts.agent_1_vision_prompts import build_vision_prompt, build_user_query

# ç¦ç”¨SSLéªŒè¯è­¦å‘Š
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


class Qwen3VLModel:
    """Qwen3-VLè§†è§‰æ¨¡å‹å°è£…ç±»"""

    def __init__(self, api_key: Optional[str] = None, model_name: Optional[str] = None):
        """
        åˆå§‹åŒ–Qwen3-VLæ¨¡å‹

        Args:
            api_key: DashScope API Keyï¼Œå¦‚æœä¸æä¾›åˆ™ä»ç¯å¢ƒå˜é‡è·å–
            model_name: æ¨¡å‹åç§°ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»config.pyè¯»å–ï¼‰
        """
        self.api_key = api_key or os.getenv("DASHSCOPE_API_KEY")
        if not self.api_key:
            raise ValueError("è¯·è®¾ç½®DASHSCOPE_API_KEYç¯å¢ƒå˜é‡æˆ–ä¼ å…¥api_keyå‚æ•°")

        self.client = OpenAI(
            api_key=self.api_key,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
        )

        # âœ… Bugä¿®å¤ï¼šä»config.pyè¯»å–æ¨¡å‹åç§°
        if model_name:
            self.model_name = model_name
        else:
            try:
                from config import MODEL_CONFIG
                self.model_name = MODEL_CONFIG["qwen"]
            except ImportError:
                self.model_name = os.getenv("QWEN_MODEL", "qwen-vl-plus")
    
    def encode_image_to_base64(self, image_path: str) -> str:
        """
        å°†å›¾ç‰‡æ–‡ä»¶ç¼–ç ä¸ºbase64æ ¼å¼
        
        Args:
            image_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„
            
        Returns:
            base64ç¼–ç çš„å›¾ç‰‡æ•°æ®URL
        """
        with open(image_path, "rb") as image_file:
            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
            return f"data:image/jpeg;base64,{encoded_string}"
    
    def analyze_engineering_drawing(
        self,
        image_path: Union[str, List[str]],
        focus_areas: Optional[List[str]] = None,
        drawing_type: str = "è£…é…å›¾",
        enable_thinking: bool = True,
        custom_system_prompt: Optional[str] = None,
        custom_user_query: Optional[str] = None
    ) -> Dict:
        """
        åˆ†æå·¥ç¨‹å›¾çº¸

        Args:
            image_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„ï¼ˆå•å¼ ï¼‰æˆ–å›¾ç‰‡è·¯å¾„åˆ—è¡¨ï¼ˆå¤šå¼ ï¼‰
            focus_areas: é‡ç‚¹å…³æ³¨é¢†åŸŸï¼Œå¯é€‰å€¼ï¼š['welding', 'assembly', 'quality']
            drawing_type: å›¾çº¸ç±»å‹æè¿°
            enable_thinking: æ˜¯å¦å¯ç”¨æ€è€ƒè¿‡ç¨‹
            custom_system_prompt: è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯ï¼Œå¦‚æœæä¾›åˆ™è¦†ç›–é»˜è®¤æç¤ºè¯
            custom_user_query: è‡ªå®šä¹‰ç”¨æˆ·æŸ¥è¯¢ï¼Œå¦‚æœæä¾›åˆ™è¦†ç›–é»˜è®¤æŸ¥è¯¢

        Returns:
            è§£æç»“æœå­—å…¸
        """
        # æ„å»ºæç¤ºè¯
        if custom_system_prompt:
            system_prompt = custom_system_prompt
        else:
            system_prompt = build_vision_prompt(focus_areas)

        if custom_user_query:
            user_query = custom_user_query
        else:
            user_query = build_user_query(
                drawing_type=drawing_type,
                focus_description="BOMè¡¨æ ¼ã€æŠ€æœ¯è¦æ±‚å’Œè£…é…å·¥è‰º"
            )

        # å‡†å¤‡å›¾ç‰‡æ•°æ®ï¼ˆæ”¯æŒå•å¼ æˆ–å¤šå¼ ï¼‰
        image_paths = [image_path] if isinstance(image_path, str) else image_path

        # æ„å»ºç”¨æˆ·æ¶ˆæ¯å†…å®¹ï¼ˆå¤šå¼ å›¾ç‰‡ï¼‰
        user_content = []

        # æ·»åŠ æ‰€æœ‰å›¾ç‰‡
        for img_path in image_paths:
            if img_path.startswith('http'):
                image_url = img_path
            else:
                image_url = self.encode_image_to_base64(img_path)

            user_content.append({
                "type": "image_url",
                "image_url": {"url": image_url}
            })

        # æ·»åŠ æ–‡æœ¬æŸ¥è¯¢
        user_content.append({
            "type": "text",
            "text": user_query
        })

        # æ„å»ºæ¶ˆæ¯
        messages = [
            {
                "role": "system",
                "content": system_prompt
            },
            {
                "role": "user",
                "content": user_content
            }
        ]
        
        try:
            # è°ƒç”¨API
            completion = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                stream=True,
                extra_body={
                    'enable_thinking': enable_thinking,
                    "thinking_budget": 1000
                }
            )
            
            # å¤„ç†æµå¼å“åº”
            reasoning_content = ""
            answer_content = ""
            is_answering = False
            
            for chunk in completion:
                if not chunk.choices:
                    continue
                    
                delta = chunk.choices[0].delta
                
                # æ”¶é›†æ€è€ƒè¿‡ç¨‹
                if hasattr(delta, 'reasoning_content') and delta.reasoning_content:
                    reasoning_content += delta.reasoning_content
                else:
                    # æ”¶é›†å›å¤å†…å®¹
                    if delta.content and not is_answering:
                        is_answering = True
                    if delta.content:
                        answer_content += delta.content
            
            # å°è¯•è§£æJSONç»“æœ
            try:
                # æå–JSONéƒ¨åˆ†
                json_start = answer_content.find('{')
                json_end = answer_content.rfind('}') + 1
                if json_start >= 0 and json_end > json_start:
                    json_str = answer_content[json_start:json_end]
                    parsed_result = json.loads(json_str)
                else:
                    parsed_result = {"raw_content": answer_content}
            except json.JSONDecodeError as e:
                # JSONè§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤
                print(f"âš ï¸ JSONè§£æå¤±è´¥: {e}")
                print(f"âš ï¸ é”™è¯¯ä½ç½®: line {e.lineno} column {e.colno}")

                # å°è¯•æå–```jsonä»£ç å—
                if "```json" in answer_content:
                    json_start = answer_content.find("```json") + 7
                    json_end = answer_content.find("```", json_start)
                    if json_end > json_start:
                        json_str = answer_content[json_start:json_end].strip()
                        try:
                            parsed_result = json.loads(json_str)
                        except:
                            parsed_result = {"raw_content": answer_content, "parse_error": str(e)}
                    else:
                        parsed_result = {"raw_content": answer_content, "parse_error": str(e)}
                else:
                    parsed_result = {"raw_content": answer_content, "parse_error": str(e)}
            
            # ä¿å­˜è¾“å‡ºç»“æœåˆ°ä¸´æ—¶æ–‡ä»¶
            import datetime
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            output_dir = "debug_output"
            os.makedirs(output_dir, exist_ok=True)

            output_file = os.path.join(output_dir, f"vision_output_{timestamp}.json")
            result_data = {
                "success": True,
                "model": self.model_name,
                "timestamp": timestamp,
                "image_path": image_path,
                "reasoning": reasoning_content,
                "result": parsed_result,
                "raw_response": answer_content
            }

            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result_data, f, ensure_ascii=False, indent=2)

            print(f"ğŸ’¾ è§†è§‰æ¨¡å‹è¾“å‡ºå·²ä¿å­˜: {output_file}")

            return {
                "success": True,
                "reasoning": reasoning_content,
                "result": parsed_result,
                "raw_response": answer_content
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "result": None
            }
    
    def batch_analyze_pdf_pages(
        self, 
        pdf_images: List[str], 
        focus_areas: Optional[List[str]] = None
    ) -> List[Dict]:
        """
        æ‰¹é‡åˆ†æPDFé¡µé¢å›¾ç‰‡
        
        Args:
            pdf_images: PDFé¡µé¢å›¾ç‰‡è·¯å¾„åˆ—è¡¨
            focus_areas: é‡ç‚¹å…³æ³¨é¢†åŸŸ
            
        Returns:
            æ¯é¡µçš„åˆ†æç»“æœåˆ—è¡¨
        """
        results = []
        
        for i, image_path in enumerate(pdf_images):
            print(f"æ­£åœ¨åˆ†æç¬¬ {i+1}/{len(pdf_images)} é¡µ...")
            
            result = self.analyze_engineering_drawing(
                image_path=image_path,
                focus_areas=focus_areas,
                drawing_type=f"å·¥ç¨‹å›¾ç¬¬{i+1}é¡µ"
            )
            
            result["page_number"] = i + 1
            result["image_path"] = image_path
            results.append(result)
        
        return results


# ä¾¿æ·å‡½æ•°
def analyze_single_drawing(
    image_path: str, 
    api_key: Optional[str] = None,
    focus_areas: Optional[List[str]] = None
) -> Dict:
    """
    åˆ†æå•å¼ å·¥ç¨‹å›¾çº¸çš„ä¾¿æ·å‡½æ•°
    
    Args:
        image_path: å›¾ç‰‡è·¯å¾„
        api_key: APIå¯†é’¥
        focus_areas: é‡ç‚¹å…³æ³¨é¢†åŸŸ
        
    Returns:
        åˆ†æç»“æœ
    """
    model = Qwen3VLModel(api_key)
    return model.analyze_engineering_drawing(image_path, focus_areas)


def analyze_pdf_drawings(
    pdf_images: List[str], 
    api_key: Optional[str] = None,
    focus_areas: Optional[List[str]] = None
) -> List[Dict]:
    """
    æ‰¹é‡åˆ†æPDFå·¥ç¨‹å›¾çº¸çš„ä¾¿æ·å‡½æ•°
    
    Args:
        pdf_images: PDFé¡µé¢å›¾ç‰‡åˆ—è¡¨
        api_key: APIå¯†é’¥
        focus_areas: é‡ç‚¹å…³æ³¨é¢†åŸŸ
        
    Returns:
        åˆ†æç»“æœåˆ—è¡¨
    """
    model = Qwen3VLModel(api_key)
    return model.batch_analyze_pdf_pages(pdf_images, focus_areas)
